# SeqSetVAE Training Guide

ç”±äºåŸæ¥çš„ç»Ÿä¸€è„šæœ¬å­˜åœ¨æ—¥å¿—å†²çªé—®é¢˜ï¼Œç°åœ¨å·²ç»åˆ†ç¦»æˆä¸¤ä¸ªç‹¬ç«‹çš„è„šæœ¬ï¼š

## ğŸš€ é¢„è®­ç»ƒ (Pretraining)

ä½¿ç”¨ `train_pretrain.py` è¿›è¡Œé¢„è®­ç»ƒï¼š

```bash
python train_pretrain.py \
    --data_dir /path/to/your/data \
    --batch_size 1 \
    --max_epochs 1000 \
    --devices 1 \
    --precision 16-mixed
```

### é¢„è®­ç»ƒå‚æ•°ï¼š
- `--data_dir`: æ•°æ®ç›®å½•è·¯å¾„ (å¿…éœ€)
- `--batch_size`: æ‰¹å¤§å° (é»˜è®¤: 1)
- `--max_epochs`: æœ€å¤§è®­ç»ƒè½®æ•° (é»˜è®¤: 1000)
- `--lr`: å­¦ä¹ ç‡ (å¯é€‰ï¼Œä½¿ç”¨configé»˜è®¤å€¼)
- `--pretrained_ckpt`: ç»§ç»­è®­ç»ƒçš„æ£€æŸ¥ç‚¹ (å¯é€‰)
- `--output_root_dir`: è¾“å‡ºç›®å½• (é»˜è®¤: outputs/)

é¢„è®­ç»ƒæ¨¡å‹ä¼šä¿å­˜åœ¨ `outputs/SeqSetVAE/pretrain/checkpoints/` ç›®å½•ä¸‹ã€‚

## ğŸ¯ å¾®è°ƒ (Finetuning)

ä½¿ç”¨ `train_finetune.py` è¿›è¡Œå¾®è°ƒï¼š

```bash
python train_finetune.py \
    --data_dir /path/to/your/data \
    --label_path /path/to/your/labels.csv \
    --pretrained_ckpt /path/to/pretrain/checkpoint.ckpt \
    --batch_size 8 \
    --max_epochs 100 \
    --devices 1 \
    --precision 16-mixed
```

### å¾®è°ƒå‚æ•°ï¼š
- `--data_dir`: æ•°æ®ç›®å½•è·¯å¾„ (å¿…éœ€)
- `--label_path`: æ ‡ç­¾æ–‡ä»¶è·¯å¾„ (å¿…éœ€)
- `--pretrained_ckpt`: é¢„è®­ç»ƒæ£€æŸ¥ç‚¹è·¯å¾„ (å¿…éœ€)
- `--batch_size`: æ‰¹å¤§å° (é»˜è®¤: 8)
- `--max_epochs`: æœ€å¤§è®­ç»ƒè½®æ•° (é»˜è®¤: 100)
- `--lr`: åŸºç¡€å­¦ä¹ ç‡ (å¯é€‰)
- `--cls_head_lr`: åˆ†ç±»å¤´å­¦ä¹ ç‡ (å¯é€‰)

å¾®è°ƒæ¨¡å‹ä¼šä¿å­˜åœ¨ `outputs/SeqSetVAE/finetune/checkpoints/` ç›®å½•ä¸‹ã€‚

## ğŸ“Š ç›‘æ§è®­ç»ƒ

ä¸¤ä¸ªè„šæœ¬éƒ½æ”¯æŒï¼š
- **TensorBoard æ—¥å¿—**: åœ¨ `outputs/SeqSetVAE/{pretrain|finetune}/logs/` ç›®å½•
- **æ£€æŸ¥ç‚¹ä¿å­˜**: è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
- **æ—©åœæœºåˆ¶**: é˜²æ­¢è¿‡æ‹Ÿåˆ
- **å­¦ä¹ ç‡ç›‘æ§**: è·Ÿè¸ªå­¦ä¹ ç‡å˜åŒ–

### æŸ¥çœ‹ TensorBoard:
```bash
tensorboard --logdir outputs/SeqSetVAE/pretrain/logs/  # é¢„è®­ç»ƒ
tensorboard --logdir outputs/SeqSetVAE/finetune/logs/  # å¾®è°ƒ
```

## ğŸ”„ å®Œæ•´è®­ç»ƒæµç¨‹

1. **é¢„è®­ç»ƒ**:
```bash
python train_pretrain.py --data_dir /your/data --max_epochs 1000
```

2. **æ‰¾åˆ°æœ€ä½³é¢„è®­ç»ƒæ£€æŸ¥ç‚¹**:
```bash
ls outputs/SeqSetVAE/pretrain/checkpoints/
```

3. **å¾®è°ƒ**:
```bash
python train_finetune.py \
    --data_dir /your/data \
    --label_path /your/labels.csv \
    --pretrained_ckpt outputs/SeqSetVAE/pretrain/checkpoints/best_checkpoint.ckpt \
    --max_epochs 100
```

## âœ… ä¼˜åŠ¿

- **æ— æ—¥å¿—å†²çª**: æ¯ä¸ªè„šæœ¬ç‹¬ç«‹è¿è¡Œï¼Œé¿å…æ—¥å¿—é‡å¤é—®é¢˜
- **æ¸…æ™°åˆ†ç¦»**: é¢„è®­ç»ƒå’Œå¾®è°ƒé€»è¾‘å®Œå…¨ç‹¬ç«‹
- **å®Œæ•´ç›‘æ§**: æ¯ä¸ªé˜¶æ®µéƒ½æœ‰å®Œæ•´çš„æŒ‡æ ‡ç›‘æ§
- **ç®€å•æ˜“ç”¨**: ä¸“é—¨çš„å‚æ•°è®¾è®¡ï¼Œå‡å°‘é…ç½®é”™è¯¯

## ğŸ“ æ³¨æ„äº‹é¡¹

1. é¢„è®­ç»ƒä¸éœ€è¦æ ‡ç­¾æ–‡ä»¶
2. å¾®è°ƒå¿…é¡»æä¾›æ ‡ç­¾æ–‡ä»¶å’Œé¢„è®­ç»ƒæ£€æŸ¥ç‚¹
3. è¾“å‡ºç›®å½•ä¼šè‡ªåŠ¨åˆ›å»º
4. æ£€æŸ¥ç‚¹è‡ªåŠ¨ä¿å­˜æœ€ä½³æ¨¡å‹
5. æ”¯æŒå¤šGPUè®­ç»ƒï¼ˆè®¾ç½® `--devices` å‚æ•°ï¼‰