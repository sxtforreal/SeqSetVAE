import torch
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from lightning.pytorch.callbacks import Callback
from lightning.pytorch import LightningModule
import warnings
from typing import Dict, List, Optional, Tuple
from collections import deque
import logging
import os
from datetime import datetime

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class PosteriorCollapseDetector(Callback):
    """
    å®æ—¶æ£€æµ‹VAEåéªŒå¡Œç¼©çš„å›è°ƒç±»
    
    ç›‘æ§å¤šä¸ªå…³é”®æŒ‡æ ‡ï¼š
    1. KLæ•£åº¦ï¼ˆæ¯å±‚å’Œæ€»ä½“ï¼‰
    2. æ½œåœ¨å˜é‡çš„æ–¹å·®
    3. æ½œåœ¨å˜é‡çš„å‡å€¼åˆ†å¸ƒ
    4. æ¿€æ´»å•å…ƒæ•°é‡
    5. é‡æ„è¯¯å·®å˜åŒ–
    """
    
    def __init__(
        self,
        # æ£€æµ‹é˜ˆå€¼
        kl_threshold: float = 0.01,          # KLæ•£åº¦è¿‡ä½é˜ˆå€¼
        var_threshold: float = 0.1,          # æ–¹å·®è¿‡ä½é˜ˆå€¼  
        active_units_threshold: float = 0.1,  # æ¿€æ´»å•å…ƒæ¯”ä¾‹é˜ˆå€¼
        
        # ç›‘æ§çª—å£
        window_size: int = 100,              # æ»‘åŠ¨çª—å£å¤§å°
        check_frequency: int = 50,           # æ£€æŸ¥é¢‘ç‡ï¼ˆæ¯Nä¸ªstepæ£€æŸ¥ä¸€æ¬¡ï¼‰
        
        # æ—©æœŸåœæ­¢
        early_stop_patience: int = 200,      # è¿ç»­å¤šå°‘æ­¥æ£€æµ‹åˆ°å¡Œç¼©ååœæ­¢
        auto_save_on_collapse: bool = True,  # æ£€æµ‹åˆ°å¡Œç¼©æ—¶è‡ªåŠ¨ä¿å­˜
        
        # è¾“å‡ºè®¾ç½®
        log_dir: str = "./collapse_logs",    # æ—¥å¿—ä¿å­˜ç›®å½•
        plot_frequency: int = 500,           # ç»˜å›¾é¢‘ç‡
        verbose: bool = True,                # æ˜¯å¦è¾“å‡ºè¯¦ç»†ä¿¡æ¯
    ):
        super().__init__()
        
        # ä¿å­˜å‚æ•°
        self.kl_threshold = kl_threshold
        self.var_threshold = var_threshold
        self.active_units_threshold = active_units_threshold
        
        self.window_size = window_size
        self.check_frequency = check_frequency
        
        self.early_stop_patience = early_stop_patience
        self.auto_save_on_collapse = auto_save_on_collapse
        
        self.log_dir = log_dir
        self.plot_frequency = plot_frequency
        self.verbose = verbose
        
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        os.makedirs(log_dir, exist_ok=True)
        
        # åˆå§‹åŒ–ç›‘æ§å˜é‡
        self.reset_monitoring_state()
        
        # è®¾ç½®æ–‡ä»¶æ—¥å¿—
        self.setup_file_logging()
        
    def reset_monitoring_state(self):
        """é‡ç½®ç›‘æ§çŠ¶æ€"""
        # å†å²æ•°æ®å­˜å‚¨ï¼ˆä½¿ç”¨dequeå®ç°æ»‘åŠ¨çª—å£ï¼‰
        self.kl_history = deque(maxlen=self.window_size)
        self.var_history = deque(maxlen=self.window_size)
        self.mean_history = deque(maxlen=self.window_size)
        self.active_units_history = deque(maxlen=self.window_size)
        self.recon_loss_history = deque(maxlen=self.window_size)
        
        # å¡Œç¼©æ£€æµ‹çŠ¶æ€
        self.collapse_detected = False
        self.collapse_step = None
        self.collapse_consecutive_steps = 0
        self.collapse_warnings = []
        
        # æ­¥æ•°è®¡æ•°
        self.global_step = 0
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.collapse_stats = {
            'total_checks': 0,
            'warnings_issued': 0,
            'false_alarms': 0,
        }
        
    def setup_file_logging(self):
        """è®¾ç½®æ–‡ä»¶æ—¥å¿—è®°å½•"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = os.path.join(self.log_dir, f"collapse_detection_{timestamp}.log")
        
        file_handler = logging.FileHandler(log_file)
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
        file_handler.setFormatter(formatter)
        
        logger.addHandler(file_handler)
        self.log_file = log_file
        
    def on_train_batch_end(self, trainer, pl_module, outputs, batch, batch_idx):
        """åœ¨æ¯ä¸ªè®­ç»ƒæ‰¹æ¬¡ç»“æŸåè¿›è¡Œæ£€æµ‹"""
        self.global_step += 1
        
        # æŒ‰é¢‘ç‡æ£€æŸ¥
        if self.global_step % self.check_frequency != 0:
            return
            
        # æå–ç›‘æ§æŒ‡æ ‡
        metrics = self.extract_monitoring_metrics(pl_module, outputs)
        if metrics is None:
            return
            
        # æ›´æ–°å†å²æ•°æ®
        self.update_history(metrics)
        
        # è¿›è¡Œå¡Œç¼©æ£€æµ‹
        collapse_detected, warnings = self.detect_collapse(metrics)
        
        # å¤„ç†æ£€æµ‹ç»“æœ
        self.handle_detection_results(trainer, pl_module, collapse_detected, warnings)
        
        # å®šæœŸç»˜å›¾å’Œä¿å­˜
        if self.global_step % self.plot_frequency == 0:
            self.save_monitoring_plots()
            
    def extract_monitoring_metrics(self, pl_module: LightningModule, outputs) -> Optional[Dict]:
        """ä»æ¨¡å‹ä¸­æå–ç›‘æ§æŒ‡æ ‡"""
        try:
            metrics = {}
            
            # 1. æå–KLæ•£åº¦ï¼ˆä»logged metricsä¸­è·å–ï¼‰
            if hasattr(pl_module, 'logged_metrics'):
                logged = pl_module.logged_metrics
                if 'train_kl' in logged:
                    metrics['kl_divergence'] = logged['train_kl'].item()
                if 'train_recon' in logged:
                    metrics['recon_loss'] = logged['train_recon'].item()
                    
            # 2. ä»æ¨¡å‹ä¸­ç›´æ¥æå–æ½œåœ¨å˜é‡ç»Ÿè®¡ä¿¡æ¯
            if hasattr(pl_module, 'setvae'):
                # è·å–æœ€è¿‘ä¸€æ¬¡å‰å‘ä¼ æ’­çš„æ½œåœ¨å˜é‡
                latent_stats = self.extract_latent_statistics(pl_module)
                if latent_stats:
                    metrics.update(latent_stats)
                    
            return metrics if metrics else None
            
        except Exception as e:
            logger.warning(f"Failed to extract metrics: {e}")
            return None
            
    def extract_latent_statistics(self, pl_module: LightningModule) -> Dict:
        """æå–æ½œåœ¨å˜é‡çš„ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        try:
            # è¿è¡Œä¸€ä¸ªå°æ‰¹æ¬¡æ¥è·å–æ½œåœ¨å˜é‡ç»Ÿè®¡
            pl_module.eval()
            with torch.no_grad():
                # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„å…·ä½“æ¨¡å‹ç»“æ„æ¥è°ƒæ•´
                # å‡è®¾æˆ‘ä»¬å¯ä»¥é€šè¿‡æŸç§æ–¹å¼è·å–æœ€è¿‘çš„æ½œåœ¨å˜é‡
                
                # å¦‚æœæ¨¡å‹æœ‰å­˜å‚¨æœ€è¿‘çš„æ½œåœ¨å˜é‡
                if hasattr(pl_module, '_last_z_list') and pl_module._last_z_list:
                    z_list = pl_module._last_z_list
                    
                    # è®¡ç®—æ¯å±‚çš„ç»Ÿè®¡ä¿¡æ¯
                    layer_vars = []
                    layer_means = []
                    active_units_ratios = []
                    
                    for layer_idx, (z_sample, mu, logvar) in enumerate(z_list):
                        # æ–¹å·®ç»Ÿè®¡
                        var = torch.exp(logvar)
                        mean_var = var.mean().item()
                        layer_vars.append(mean_var)
                        
                        # å‡å€¼ç»Ÿè®¡
                        mean_abs_mu = torch.abs(mu).mean().item()
                        layer_means.append(mean_abs_mu)
                        
                        # æ¿€æ´»å•å…ƒç»Ÿè®¡ï¼ˆæ–¹å·®å¤§äºé˜ˆå€¼çš„å•å…ƒæ¯”ä¾‹ï¼‰
                        active_ratio = (var.mean(0) > self.var_threshold).float().mean().item()
                        active_units_ratios.append(active_ratio)
                        
                    stats['layer_variances'] = layer_vars
                    stats['layer_mean_magnitudes'] = layer_means
                    stats['active_units_ratios'] = active_units_ratios
                    
                    # æ€»ä½“ç»Ÿè®¡
                    stats['mean_variance'] = np.mean(layer_vars)
                    stats['mean_active_ratio'] = np.mean(active_units_ratios)
                    
            pl_module.train()
            return stats
            
        except Exception as e:
            logger.warning(f"Failed to extract latent statistics: {e}")
            return {}
            
    def update_history(self, metrics: Dict):
        """æ›´æ–°å†å²æ•°æ®"""
        if 'kl_divergence' in metrics:
            self.kl_history.append(metrics['kl_divergence'])
            
        if 'mean_variance' in metrics:
            self.var_history.append(metrics['mean_variance'])
            
        if 'mean_active_ratio' in metrics:
            self.active_units_history.append(metrics['mean_active_ratio'])
            
        if 'recon_loss' in metrics:
            self.recon_loss_history.append(metrics['recon_loss'])
            
        if 'layer_mean_magnitudes' in metrics:
            avg_mean_mag = np.mean(metrics['layer_mean_magnitudes'])
            self.mean_history.append(avg_mean_mag)
            
    def detect_collapse(self, metrics: Dict) -> Tuple[bool, List[str]]:
        """æ£€æµ‹åéªŒå¡Œç¼©"""
        warnings = []
        collapse_indicators = 0
        
        self.collapse_stats['total_checks'] += 1
        
        # 1. KLæ•£åº¦æ£€æµ‹
        if 'kl_divergence' in metrics:
            kl_val = metrics['kl_divergence']
            if kl_val < self.kl_threshold:
                warnings.append(f"KLæ•£åº¦è¿‡ä½: {kl_val:.6f} < {self.kl_threshold}")
                collapse_indicators += 1
                
            # æ£€æŸ¥KLæ•£åº¦è¶‹åŠ¿
            if len(self.kl_history) >= 20:
                recent_kl = list(self.kl_history)[-20:]
                if all(kl < self.kl_threshold for kl in recent_kl):
                    warnings.append("KLæ•£åº¦æŒç»­è¿‡ä½ï¼ˆæœ€è¿‘20æ­¥ï¼‰")
                    collapse_indicators += 2
                    
        # 2. æ–¹å·®æ£€æµ‹
        if 'mean_variance' in metrics:
            var_val = metrics['mean_variance']
            if var_val < self.var_threshold:
                warnings.append(f"æ½œåœ¨å˜é‡æ–¹å·®è¿‡ä½: {var_val:.6f} < {self.var_threshold}")
                collapse_indicators += 1
                
        # 3. æ¿€æ´»å•å…ƒæ£€æµ‹
        if 'mean_active_ratio' in metrics:
            active_ratio = metrics['mean_active_ratio']
            if active_ratio < self.active_units_threshold:
                warnings.append(f"æ¿€æ´»å•å…ƒæ¯”ä¾‹è¿‡ä½: {active_ratio:.3f} < {self.active_units_threshold}")
                collapse_indicators += 1
                
        # 4. é‡æ„æŸå¤±è¶‹åŠ¿æ£€æµ‹
        if len(self.recon_loss_history) >= 50:
            recent_recon = list(self.recon_loss_history)[-50:]
            recon_trend = np.polyfit(range(len(recent_recon)), recent_recon, 1)[0]
            if recon_trend > 0.001:  # é‡æ„æŸå¤±æŒç»­ä¸Šå‡
                warnings.append(f"é‡æ„æŸå¤±æŒç»­ä¸Šå‡ï¼Œè¶‹åŠ¿: {recon_trend:.6f}")
                collapse_indicators += 1
                
        # ç»¼åˆåˆ¤æ–­
        collapse_detected = collapse_indicators >= 2  # è‡³å°‘2ä¸ªæŒ‡æ ‡å¼‚å¸¸æ‰åˆ¤å®šä¸ºå¡Œç¼©
        
        if warnings:
            self.collapse_stats['warnings_issued'] += 1
            
        return collapse_detected, warnings
        
    def handle_detection_results(self, trainer, pl_module, collapse_detected: bool, warnings: List[str]):
        """å¤„ç†æ£€æµ‹ç»“æœ"""
        
        if warnings and self.verbose:
            warning_msg = f"Step {self.global_step}: åéªŒå¡Œç¼©è­¦å‘Šï¼\n" + "\n".join(f"  - {w}" for w in warnings)
            logger.warning(warning_msg)
            print(f"\nâš ï¸  {warning_msg}")
            
        if collapse_detected:
            self.collapse_consecutive_steps += 1
            
            if not self.collapse_detected:
                self.collapse_detected = True
                self.collapse_step = self.global_step
                
                collapse_msg = f"ğŸš¨ æ£€æµ‹åˆ°åéªŒå¡Œç¼©ï¼Step: {self.global_step}"
                logger.error(collapse_msg)
                print(f"\n{collapse_msg}")
                
                # è‡ªåŠ¨ä¿å­˜æ¨¡å‹
                if self.auto_save_on_collapse:
                    self.save_model_on_collapse(trainer, pl_module)
                    
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ—©æœŸåœæ­¢
            if self.collapse_consecutive_steps >= self.early_stop_patience:
                stop_msg = f"è¿ç»­{self.early_stop_patience}æ­¥æ£€æµ‹åˆ°åéªŒå¡Œç¼©ï¼Œå»ºè®®åœæ­¢è®­ç»ƒï¼"
                logger.error(stop_msg)
                print(f"\nğŸ›‘ {stop_msg}")
                
                # è¿™é‡Œå¯ä»¥è®¾ç½®trainer.should_stop = Trueæ¥åœæ­¢è®­ç»ƒ
                # ä½†ä¸ºäº†å®‰å…¨èµ·è§ï¼Œæˆ‘ä»¬åªè®°å½•å»ºè®®
                
        else:
            # é‡ç½®è¿ç»­å¡Œç¼©è®¡æ•°
            if self.collapse_consecutive_steps > 0:
                self.collapse_consecutive_steps = 0
                
                if self.collapse_detected:
                    recovery_msg = f"åéªŒå¡Œç¼©çŠ¶æ€æ¢å¤ï¼ŒStep: {self.global_step}"
                    logger.info(recovery_msg)
                    print(f"\nâœ… {recovery_msg}")
                    
    def save_model_on_collapse(self, trainer, pl_module):
        """åœ¨æ£€æµ‹åˆ°å¡Œç¼©æ—¶ä¿å­˜æ¨¡å‹"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            save_path = os.path.join(self.log_dir, f"model_before_collapse_step_{self.global_step}_{timestamp}.ckpt")
            
            trainer.save_checkpoint(save_path)
            logger.info(f"æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
            print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {save_path}")
            
        except Exception as e:
            logger.error(f"ä¿å­˜æ¨¡å‹å¤±è´¥: {e}")
            
    def save_monitoring_plots(self):
        """ä¿å­˜ç›‘æ§å›¾è¡¨"""
        try:
            fig, axes = plt.subplots(2, 2, figsize=(15, 10))
            fig.suptitle(f'åéªŒå¡Œç¼©ç›‘æ§ - Step {self.global_step}', fontsize=16)
            
            # KLæ•£åº¦å†å²
            if self.kl_history:
                axes[0, 0].plot(list(self.kl_history))
                axes[0, 0].axhline(y=self.kl_threshold, color='r', linestyle='--', alpha=0.7)
                axes[0, 0].set_title('KLæ•£åº¦å†å²')
                axes[0, 0].set_ylabel('KL Divergence')
                axes[0, 0].grid(True, alpha=0.3)
                
            # æ–¹å·®å†å²
            if self.var_history:
                axes[0, 1].plot(list(self.var_history), color='orange')
                axes[0, 1].axhline(y=self.var_threshold, color='r', linestyle='--', alpha=0.7)
                axes[0, 1].set_title('æ½œåœ¨å˜é‡æ–¹å·®å†å²')
                axes[0, 1].set_ylabel('Mean Variance')
                axes[0, 1].grid(True, alpha=0.3)
                
            # æ¿€æ´»å•å…ƒæ¯”ä¾‹å†å²
            if self.active_units_history:
                axes[1, 0].plot(list(self.active_units_history), color='green')
                axes[1, 0].axhline(y=self.active_units_threshold, color='r', linestyle='--', alpha=0.7)
                axes[1, 0].set_title('æ¿€æ´»å•å…ƒæ¯”ä¾‹å†å²')
                axes[1, 0].set_ylabel('Active Units Ratio')
                axes[1, 0].grid(True, alpha=0.3)
                
            # é‡æ„æŸå¤±å†å²
            if self.recon_loss_history:
                axes[1, 1].plot(list(self.recon_loss_history), color='purple')
                axes[1, 1].set_title('é‡æ„æŸå¤±å†å²')
                axes[1, 1].set_ylabel('Reconstruction Loss')
                axes[1, 1].grid(True, alpha=0.3)
                
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plot_path = os.path.join(self.log_dir, f"monitoring_plot_step_{self.global_step}_{timestamp}.png")
            plt.savefig(plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            if self.verbose:
                print(f"ğŸ“Š ç›‘æ§å›¾è¡¨å·²ä¿å­˜: {plot_path}")
                
        except Exception as e:
            logger.warning(f"ä¿å­˜ç›‘æ§å›¾è¡¨å¤±è´¥: {e}")
            
    def on_train_end(self, trainer, pl_module):
        """è®­ç»ƒç»“æŸæ—¶çš„æ€»ç»“"""
        summary_msg = f"""
        
ğŸ¯ åéªŒå¡Œç¼©æ£€æµ‹æ€»ç»“:
===================
æ€»æ£€æŸ¥æ¬¡æ•°: {self.collapse_stats['total_checks']}
å‘å‡ºè­¦å‘Šæ¬¡æ•°: {self.collapse_stats['warnings_issued']}
æ£€æµ‹åˆ°å¡Œç¼©: {'æ˜¯' if self.collapse_detected else 'å¦'}
å¡Œç¼©å‘ç”Ÿæ­¥æ•°: {self.collapse_step if self.collapse_step else 'N/A'}
æ—¥å¿—æ–‡ä»¶: {self.log_file}
        """
        
        logger.info(summary_msg)
        print(summary_msg)
        
        # ä¿å­˜æœ€ç»ˆç»Ÿè®¡ä¿¡æ¯
        stats_file = os.path.join(self.log_dir, "final_statistics.txt")
        with open(stats_file, 'w', encoding='utf-8') as f:
            f.write(summary_msg)
            f.write(f"\næ£€æµ‹å‚æ•°:\n")
            f.write(f"KLé˜ˆå€¼: {self.kl_threshold}\n")
            f.write(f"æ–¹å·®é˜ˆå€¼: {self.var_threshold}\n") 
            f.write(f"æ¿€æ´»å•å…ƒé˜ˆå€¼: {self.active_units_threshold}\n")
            f.write(f"æ£€æŸ¥é¢‘ç‡: {self.check_frequency}\n")
            f.write(f"æ—©æœŸåœæ­¢è€å¿ƒ: {self.early_stop_patience}\n")


# è¾…åŠ©å‡½æ•°ï¼šä¸ºç°æœ‰æ¨¡å‹æ·»åŠ æ½œåœ¨å˜é‡è·Ÿè¸ª
def add_latent_tracking_to_model(model):
    """ä¸ºæ¨¡å‹æ·»åŠ æ½œåœ¨å˜é‡è·Ÿè¸ªåŠŸèƒ½"""
    
    original_forward = model.forward
    
    def tracked_forward(self, *args, **kwargs):
        result = original_forward(*args, **kwargs)
        
        # å¦‚æœæ¨¡å‹æœ‰setvaeå±æ€§ï¼Œå°è¯•è·å–æ½œåœ¨å˜é‡ä¿¡æ¯
        if hasattr(self, 'setvae') and hasattr(self.setvae, '_last_z_list'):
            self._last_z_list = self.setvae._last_z_list
            
        return result
        
    # æ›¿æ¢forwardæ–¹æ³•
    model.forward = tracked_forward.__get__(model, model.__class__)
    
    return model


# ä½¿ç”¨ç¤ºä¾‹å’Œæµ‹è¯•å‡½æ•°
def test_detector():
    """æµ‹è¯•æ£€æµ‹å™¨åŠŸèƒ½"""
    detector = PosteriorCollapseDetector(
        kl_threshold=0.01,
        var_threshold=0.1,
        check_frequency=10,
        verbose=True
    )
    
    print("âœ… åéªŒå¡Œç¼©æ£€æµ‹å™¨åˆ›å»ºæˆåŠŸï¼")
    print(f"ğŸ“ æ—¥å¿—ç›®å½•: {detector.log_dir}")
    print(f"ğŸ” æ£€æµ‹å‚æ•°:")
    print(f"  - KLé˜ˆå€¼: {detector.kl_threshold}")
    print(f"  - æ–¹å·®é˜ˆå€¼: {detector.var_threshold}")
    print(f"  - æ£€æŸ¥é¢‘ç‡: æ¯{detector.check_frequency}æ­¥")
    
    return detector

if __name__ == "__main__":
    test_detector()