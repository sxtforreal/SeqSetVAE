å®žéªŒè®¡åˆ’è„šæœ¬ï¼ˆStage 1â€“3ï¼‰

æ•°æ®æœŸæœ›æ ¼å¼ï¼šå•ä¸ª `.npz` æ–‡ä»¶åŒ…å«é”®ï¼š`mu[B,T,D]`ï¼Œ`logvar[B,T,D]`ï¼Œ`dt[B,T,1]`ï¼ˆæˆ– `[B,T]`ï¼‰ï¼Œ`mask[B,T]`ï¼ˆ0/1ï¼‰ï¼Œ`y[B]`ã€‚

å¿«é€Ÿå¼€å§‹ï¼š

1) å®‰è£…ä¾èµ–

```bash
pip install -r requirements.txt
```

2) è¿è¡Œ Stage 1ï¼šçº¿æ€§æŽ¢é’ˆä¸Žé¡ºåº/ä¸ç¡®å®šæ€§æ£€éªŒ

```bash
python stage1.py --data_path /path/to/data.npz --out_dir runs/stage1
```

3) è¿è¡Œ Stage 2ï¼šå€™é€‰è·¯çº¿æœ€å°å®žçŽ°å¯¹æ¯”ï¼ˆä»Ž Aâ€“F ä¸­é€‰æ‹©ï¼‰

```bash
python stage2.py --data_path /path/to/data.npz --out_dir runs/stage2 --routes A,B,C
```

4) è¿è¡Œ Stage 3ï¼šè¯Šæ–­æ€§æ¶ˆèžï¼ˆè¿‘æœŸ vs è¿œæœŸã€é¡ºåºæ•æ„Ÿã€ä¸ç¡®å®šæ€§è´¡çŒ®/å®½åº¦ï¼‰

```bash
python stage3.py --data_path /path/to/data.npz --out_dir runs/stage3 --best_routes A,C
```

å¤‡æ³¨
- ä¸»æŒ‡æ ‡ä¸º AUPRCï¼ˆVal ä¸Šæ—©åœï¼‰ã€‚åŒæ—¶æŠ¥å‘Š AUROCã€Recall@Precisionâ‰¥{0.6,0.7}ã€Precision@Top-k å’Œ ECEï¼ˆå¯é€‰ï¼‰ã€‚
- æ‰€æœ‰è„šæœ¬å‡æ”¯æŒå¤šæ¬¡éšæœºç§å­é‡å¤ï¼ˆé»˜è®¤ 3 æ¬¡ï¼‰å¹¶è¾“å‡ºè¡¨æ ¼æ±‡æ€»ã€‚
 - æ•°æ®é”®åå¯é€šè¿‡ç®€å•ä¿®æ”¹ `exp/utils.py` ä¸Ž `exp/data.py` é€‚é…ã€‚
# SeqSetVAE

Unified training interface with two modes and **advanced VAE feature fusion** (2024 update):

## Training Modes

- Pretrain (reconstruction+KL only, strict causal):
  ```bash
  python3 train.py --mode pretrain \
    --data_dir /path/to/patient_ehr \
    --params_map_path /path/to/stats.csv \
    --label_path /path/to/oc.csv
  ```
  - Batch: single patient per batch
  - Monitor: val_loss
  - Checkpoints: best + last, validated every 10% epoch

- Finetune (classification only with **uncertainty-aware VAE fusion**):
  ```bash
  python3 train.py --mode finetune \
    --pretrained_ckpt /path/to/pretrain.ckpt \
    --batch_size 8 \
    --data_dir /path/to/patient_ehr \
    --params_map_path /path/to/stats.csv \
    --label_path /path/to/oc.csv \
    --vae_fusion_method enhanced_concat \
    --estimate_uncertainty
  ```
  - Batch: multi-patient
  - Backbone frozen and set to eval; only `cls_head` is trained with higher LR
  - Monitor: val_auc
  - Checkpoints: best + last, validated every 10% epoch

## ðŸŽ¯ Simple & Effective VAE Feature Fusion

Based on empirical evidence that **simple approaches often work best** in medical domains, we provide two optimized methods:

### Available Fusion Methods

1. **Simple Concatenation** (`simple_concat`) - **Recommended for stability**
   - Basic mean + std concatenation
   - Proven effective, minimal complexity
   - Best for medical data where robustness > complexity

2. **Enhanced Concatenation** (`enhanced_concat`) - **Try if you need more**
   - Adds 2 key uncertainty features: total variance + mean magnitude
   - Minimal overhead, targeted improvements
   - Only use if simple version is not sufficient

### Usage Examples

#### Recommended: Simple & Robust
```bash
python3 train.py --mode finetune \
  --pretrained_ckpt model.ckpt \
  --vae_fusion_method simple_concat
```

#### Optional: Enhanced with Minimal Uncertainty
```bash
python3 train.py --mode finetune \
  --pretrained_ckpt model.ckpt \
  --vae_fusion_method enhanced_concat \
  --estimate_uncertainty
```

### ðŸ“Š Design Philosophy

- **Simplicity First**: Avoid over-engineering for medical data
- **Proven Methods**: Focus on well-established techniques
- **Minimal Overhead**: Add complexity only when clearly beneficial
- **Medical-Friendly**: Prioritize interpretability and robustness

### ðŸ”§ Technical Details

- **Feature Dimensionality**: 
  - Simple: 2Ã—latent_dim (mean + std)
  - Enhanced: 2Ã—latent_dim + 2 (+ total variance + mean magnitude)
- **Uncertainty**: Optional light dropout (0.1) for basic regularization
- **Temperature Scaling**: Single parameter for calibration (if uncertainty enabled)

Notes:
- Time/position encoding is unified across modes with robust design: sinusoidal index + relative time buckets + ALiBi time bias, strict causal mask.
- For dataset structure and collate details, see `dataset.py`.
- **Focal loss** remains the only classification loss for handling class imbalance.