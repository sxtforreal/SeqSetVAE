# SeqSetVAE è®­ç»ƒä¼˜åŒ–é¡¹ç›®

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬é¡¹ç›®æ˜¯ä¸€ä¸ªåŸºäºPyTorch Lightningçš„SeqSetVAEæ¨¡å‹è®­ç»ƒç³»ç»Ÿï¼Œä¸“æ³¨äºåŒ»ç–—æ—¶åºæ•°æ®çš„è¡¨ç¤ºå­¦ä¹ å’Œåˆ†ç±»ä»»åŠ¡ã€‚é¡¹ç›®åŒ…å«å®Œæ•´çš„è®­ç»ƒæµç¨‹ã€æ€§èƒ½ä¼˜åŒ–ã€åéªŒå¡Œç¼©æ£€æµ‹å’Œå¯è§†åŒ–åˆ†æåŠŸèƒ½ã€‚

## ğŸš€ ä¸»è¦åŠŸèƒ½

### 1. è®­ç»ƒä¼˜åŒ–
- **é«˜æ€§èƒ½è®­ç»ƒ**ï¼šæ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒã€æ¢¯åº¦ç´¯ç§¯ã€æ¨¡å‹ç¼–è¯‘ç­‰ä¼˜åŒ–
- **æ•°æ®åŠ è½½ä¼˜åŒ–**ï¼šå¤šè¿›ç¨‹æ•°æ®åŠ è½½ã€å†…å­˜å›ºå®šã€åŠ¨æ€å¡«å……
- **ç›‘æ§å¼€é”€ä¼˜åŒ–**ï¼šå¯é…ç½®çš„ç›‘æ§é¢‘ç‡ã€å¯é€‰çš„åéªŒæŒ‡æ ‡ç›‘æ§

### 2. åéªŒå¡Œç¼©æ£€æµ‹
- **å®æ—¶ç›‘æ§**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§KLæ•£åº¦ã€æ½œåœ¨å˜é‡æ–¹å·®ç­‰å…³é”®æŒ‡æ ‡
- **å¯è§†åŒ–åˆ†æ**ï¼šè‡ªåŠ¨ç”Ÿæˆç›‘æ§å›¾è¡¨å’Œåˆ†ææŠ¥å‘Š
- **é¢„è­¦æœºåˆ¶**ï¼šåŠæ—¶å‘ç°åéªŒå¡Œç¼©é—®é¢˜

### 3. å¯è§†åŒ–åˆ†æ
- **è®­ç»ƒæ›²çº¿åˆ†æ**ï¼šæŸå¤±å‡½æ•°ã€æ€§èƒ½æŒ‡æ ‡ã€è®­ç»ƒåŠ¨æ€çš„å¯è§†åŒ–
- **æ¨¡å‹å¯è§†åŒ–**ï¼šéšç©ºé—´åˆ†æã€é‡å»ºè´¨é‡è¯„ä¼°
- **å®æ—¶ç›‘æ§**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­çš„å®æ—¶æŒ‡æ ‡æ˜¾ç¤º

## ğŸ“ æ ¸å¿ƒæ–‡ä»¶

### è®­ç»ƒç›¸å…³
- `train_optimized.py` - **ä¼˜åŒ–ç‰ˆæœ¬è®­ç»ƒè„šæœ¬**ï¼ˆæ¨èä½¿ç”¨ï¼‰
- `model.py` - SeqSetVAEæ¨¡å‹å®šä¹‰
- `dataset.py` - æ•°æ®åŠ è½½å™¨ï¼ˆå·²ä¼˜åŒ–ï¼‰
- `modules.py` - æ¨¡å‹ç»„ä»¶
- `config.py` - é…ç½®æ–‡ä»¶

### ç›‘æ§å’Œåˆ†æ
- `posterior_collapse_detector.py` - åéªŒæŒ‡æ ‡ç›‘æ§å™¨
- `analyze_training_curves.py` - è®­ç»ƒæ›²çº¿åˆ†æå·¥å…·
- `visualize_model.py` - æ¨¡å‹å¯è§†åŒ–å·¥å…·
- `collapse_visualizer.py` - å®æ—¶å¯è§†åŒ–å·¥å…·

## ğŸ¯ å¿«é€Ÿå¼€å§‹

### 1. ä¼˜åŒ–è®­ç»ƒï¼ˆæ¨èï¼‰

```bash
# å¿«é€Ÿè®­ç»ƒé…ç½®
python train_optimized.py \
    --batch_size 4 \
    --num_workers 8 \
    --pin_memory \
    --gradient_accumulation_steps 2 \
    --max_sequence_length 1000 \
    --precision 16-mixed \
    --fast_detection

### 2. ä»checkpointç»§ç»­è®­ç»ƒ

```bash
# ä»ä¸Šæ¬¡è®­ç»ƒçš„checkpointç»§ç»­è®­ç»ƒ
python train_optimized.py \
    --batch_size 4 \
    --num_workers 8 \
    --pin_memory \
    --gradient_accumulation_steps 2 \
    --max_sequence_length 1000 \
    --precision 16-mixed \
    --fast_detection \
    --resume_from_checkpoint /path/to/checkpoint.ckpt

# ä»æœ€æ–°çš„checkpointç»§ç»­è®­ç»ƒï¼ˆé€šå¸¸ä¿å­˜åœ¨outputs/checkpoints/ç›®å½•ä¸‹ï¼‰
python train_optimized.py \
    --resume_from_checkpoint /home/sunx/data/aiiih/projects/sunx/projects/TEEMR/PT/outputs/checkpoints/last.ckpt \
    --batch_size 4 \
    --fast_detection
```

**Checkpointæ–‡ä»¶è¯´æ˜ï¼š**
- `last.ckpt` - æœ€åä¸€ä¸ªepochçš„checkpoint
- `best_*.ckpt` - æœ€ä½³æ€§èƒ½çš„checkpointï¼ˆåŸºäºéªŒè¯AUCï¼‰
- `final_*.ckpt` - è®­ç»ƒå®Œæˆåçš„æœ€ç»ˆæ¨¡å‹
- `interrupted_*.ckpt` - è®­ç»ƒä¸­æ–­æ—¶ä¿å­˜çš„æ¨¡å‹
- `error_*.ckpt` - è®­ç»ƒå‡ºé”™æ—¶ä¿å­˜çš„æ¨¡å‹

**æ³¨æ„äº‹é¡¹ï¼š**
1. ç¡®ä¿checkpointæ–‡ä»¶è·¯å¾„æ­£ç¡®ä¸”æ–‡ä»¶å­˜åœ¨
2. ç»§ç»­è®­ç»ƒæ—¶ä¼šä¿æŒåŸæœ‰çš„è®­ç»ƒçŠ¶æ€ï¼ˆepochã€ä¼˜åŒ–å™¨çŠ¶æ€ç­‰ï¼‰
3. å¯ä»¥ä¿®æ”¹è®­ç»ƒå‚æ•°ï¼ˆå¦‚batch_sizeã€learning_rateç­‰ï¼‰
4. å»ºè®®ä½¿ç”¨ç›¸åŒçš„æ¨¡å‹é…ç½®å‚æ•°ä»¥ç¡®ä¿å…¼å®¹æ€§

### 3. å¸¦ç›‘æ§çš„è®­ç»ƒ

```bash
# å¸¦åéªŒæŒ‡æ ‡ç›‘æ§çš„è®­ç»ƒ
python train_optimized.py \
    --batch_size 4 \
    --fast_detection
```

### 4. æ€§èƒ½æµ‹è¯•

```bash
# æŸ¥çœ‹è¯¦ç»†çš„ä¼˜åŒ–æŒ‡å—
cat README.md
```

## ğŸ“Š æ€§èƒ½æå‡

ä½¿ç”¨ä¼˜åŒ–é…ç½®åï¼Œé¢„æœŸå¯ä»¥è·å¾— **2-3å€** çš„è®­ç»ƒé€Ÿåº¦æå‡ï¼š

| ä¼˜åŒ–æªæ–½ | é¢„æœŸé€Ÿåº¦æå‡ | å†…å­˜ä½¿ç”¨å˜åŒ– |
|---------|-------------|-------------|
| å¢åŠ æ‰¹å¤„ç†å¤§å° (1â†’4) | 30-50% | +50% |
| å¢åŠ å·¥ä½œè¿›ç¨‹æ•° (2â†’8) | 20-30% | +10% |
| æ··åˆç²¾åº¦è®­ç»ƒ | 20-40% | -30% |
| æ¢¯åº¦ç´¯ç§¯ | 10-20% | æ— å˜åŒ– |
| æ¨¡å‹ç¼–è¯‘ | 10-25% | æ— å˜åŒ– |
| å‡å°‘ç›‘æ§é¢‘ç‡ | 5-15% | -10% |
| é™åˆ¶åºåˆ—é•¿åº¦ | 20-40% | -40% |

## ğŸ”§ ç³»ç»Ÿè¦æ±‚

- Python 3.8+
- PyTorch 2.0+ï¼ˆæ¨èï¼Œæ”¯æŒæ¨¡å‹ç¼–è¯‘ï¼‰
- PyTorch Lightning
- CUDAæ”¯æŒï¼ˆæ¨èï¼‰
- 8GB+ GPUå†…å­˜ï¼ˆæ¨èï¼‰

---

# è®­ç»ƒé€Ÿåº¦ä¼˜åŒ–å®Œæ•´æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [ä¼˜åŒ–æªæ–½](#ä¼˜åŒ–æªæ–½)
3. [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
4. [æ€§èƒ½åŸºå‡†](#æ€§èƒ½åŸºå‡†)
5. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
6. [é«˜çº§æŠ€å·§](#é«˜çº§æŠ€å·§)
7. [å®ç°ç»†èŠ‚](#å®ç°ç»†èŠ‚)
8. [æ€»ç»“](#æ€»ç»“)

## ğŸ¯ æ¦‚è¿°

æœ¬æŒ‡å—æä¾›äº†å¤šç§ä¼˜åŒ–è®­ç»ƒé€Ÿåº¦çš„æ–¹æ³•ï¼ŒåŸºäºå¯¹å½“å‰ä»£ç çš„æ·±å…¥åˆ†æï¼Œä¸»è¦ä»ä»¥ä¸‹å‡ ä¸ªæ–¹é¢è¿›è¡Œä¼˜åŒ–ï¼š

1. **æ•°æ®åŠ è½½ä¼˜åŒ–** - æé«˜æ•°æ®åŠ è½½æ•ˆç‡
2. **æ¨¡å‹è®­ç»ƒä¼˜åŒ–** - ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹
3. **ç›‘æ§å¼€é”€ä¼˜åŒ–** - å‡å°‘ç›‘æ§å¼€é”€
4. **å†…å­˜ä½¿ç”¨ä¼˜åŒ–** - ä¼˜åŒ–å†…å­˜ä½¿ç”¨

### é¢„æœŸæ€§èƒ½æå‡

ä½¿ç”¨æ‰€æœ‰ä¼˜åŒ–æªæ–½åï¼Œé¢„æœŸå¯ä»¥è·å¾— **2-3å€** çš„è®­ç»ƒé€Ÿåº¦æå‡ã€‚

## ğŸš€ ä¼˜åŒ–æªæ–½

### 1. æ•°æ®åŠ è½½ä¼˜åŒ–

#### âœ… å·²å®Œæˆ
- **å¢åŠ æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°**ï¼šä»2-4ä¸ªå¢åŠ åˆ°8ä¸ª
- **å¯ç”¨å†…å­˜å›ºå®š**ï¼šä½¿ç”¨`pin_memory=True`åŠ é€ŸCPUåˆ°GPUæ•°æ®ä¼ è¾“
- **æŒä¹…åŒ–å·¥ä½œè¿›ç¨‹**ï¼šä½¿ç”¨`persistent_workers=True`é¿å…é‡å¤åˆ›å»ºè¿›ç¨‹
- **é™åˆ¶åºåˆ—é•¿åº¦**ï¼šé»˜è®¤é™åˆ¶ä¸º1000ï¼Œå¯é…ç½®
- **åŠ¨æ€å¡«å……**ï¼šå‡å°‘å†…å­˜ä½¿ç”¨å’Œè®¡ç®—å¼€é”€

#### ğŸ”§ å®ç°ç»†èŠ‚
```python
# åœ¨dataset.pyä¸­æ›´æ–°äº†_create_loaderæ–¹æ³•
def _create_loader(self, ds, shuffle=False):
    num_workers = getattr(self, 'num_workers', 4 if self.batch_size > 1 else 2)
    pin_memory = getattr(self, 'pin_memory', True)
    
    return DataLoader(
        ds,
        batch_size=self.batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        collate_fn=collate_fn,
        pin_memory=pin_memory,
        drop_last=False,
        persistent_workers=True if num_workers > 0 else False,
    )
```

#### ä½¿ç”¨ç¤ºä¾‹
```bash
# ä½¿ç”¨æ›´å¤šçš„å·¥ä½œè¿›ç¨‹æ¥å¹¶è¡ŒåŠ è½½æ•°æ®
python train_optimized.py --num_workers 8

# å¯ç”¨pin_memoryä»¥åŠ é€ŸCPUåˆ°GPUçš„æ•°æ®ä¼ è¾“
python train_optimized.py --pin_memory

# é™åˆ¶æœ€å¤§åºåˆ—é•¿åº¦ä»¥å‡å°‘å†…å­˜ä½¿ç”¨å’Œè®¡ç®—æ—¶é—´
python train_optimized.py --max_sequence_length 1000

# ä½¿ç”¨æ›´å¤§çš„æ‰¹å¤„ç†å¤§å°ä»¥æé«˜GPUåˆ©ç”¨ç‡
python train_optimized.py --batch_size 4
```

### 2. æ¨¡å‹è®­ç»ƒä¼˜åŒ–

#### âœ… å·²å®Œæˆ
- **æ··åˆç²¾åº¦è®­ç»ƒ**ï¼šé»˜è®¤ä½¿ç”¨16ä½æ··åˆç²¾åº¦
- **æ¢¯åº¦ç´¯ç§¯**ï¼šæ”¯æŒæ¢¯åº¦ç´¯ç§¯æ¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹å¤„ç†å¤§å°
- **æ¨¡å‹ç¼–è¯‘**ï¼šæ”¯æŒPyTorch 2.0+çš„`torch.compile`
- **å‡å°‘éªŒè¯é¢‘ç‡**ï¼šä»0.05å¢åŠ åˆ°0.1
- **å‡å°‘éªŒè¯æ‰¹æ¬¡**ï¼šä»0.2å‡å°‘åˆ°0.1
- **ç¦ç”¨ä¸å¿…è¦çš„åŠŸèƒ½**ï¼šå…³é—­anomaly detectionã€model summaryç­‰

#### ğŸ”§ å®ç°ç»†èŠ‚
```python
# åœ¨train_optimized.pyä¸­çš„traineré…ç½®
trainer = pl.Trainer(
    precision=args.precision,  # 16-mixed
    accumulate_grad_batches=args.gradient_accumulation_steps,
    val_check_interval=0.1,  # å‡å°‘éªŒè¯é¢‘ç‡
    limit_val_batches=0.1,   # å‡å°‘éªŒè¯æ‰¹æ¬¡
    detect_anomaly=False,    # å…³é—­anomaly detection
    enable_model_summary=False,  # å…³é—­model summary
    sync_batchnorm=False,  # å…³é—­sync batchnorm
)
```

#### ä½¿ç”¨ç¤ºä¾‹
```bash
# ä½¿ç”¨16ä½æ··åˆç²¾åº¦è®­ç»ƒï¼ˆé»˜è®¤å·²å¯ç”¨ï¼‰
python train_optimized.py --precision 16-mixed

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¥æ¨¡æ‹Ÿæ›´å¤§çš„æ‰¹å¤„ç†å¤§å°
python train_optimized.py --gradient_accumulation_steps 2

# ä½¿ç”¨torch.compileä¼˜åŒ–æ¨¡å‹ï¼ˆéœ€è¦PyTorch 2.0+ï¼‰
python train_optimized.py --compile_model
```

### 3. ç›‘æ§å¼€é”€ä¼˜åŒ–

#### âœ… å·²å®Œæˆ
- **å‡å°‘ç›‘æ§é¢‘ç‡**ï¼šä»20-50æ­¥å¢åŠ åˆ°100-200æ­¥
- **å‡å°‘ç»˜å›¾é¢‘ç‡**ï¼šä»200-500æ­¥å¢åŠ åˆ°1000-2000æ­¥
- **å‡å°‘å†å²çª—å£å¤§å°**ï¼šä»100å‡å°‘åˆ°50
- **ç¦ç”¨è¯¦ç»†è¾“å‡º**ï¼šå…³é—­verboseæ¨¡å¼
- **å¯é€‰ç›‘æ§**ï¼šæ”¯æŒå®Œå…¨ç¦ç”¨ç›‘æ§

#### ğŸ”§ å®ç°ç»†èŠ‚
```python
# åœ¨train_optimized.pyä¸­çš„ç›‘æ§é…ç½®
monitor = PosteriorMetricsMonitor(
    update_frequency=100,         # å‡å°‘æ›´æ–°é¢‘ç‡
    plot_frequency=1000,          # å‡å°‘ç»˜å›¾é¢‘ç‡
    window_size=50,               # å‡å°‘çª—å£å¤§å°
    verbose=False,                # å…³é—­è¯¦ç»†è¾“å‡º
)
```

#### ä½¿ç”¨ç¤ºä¾‹
```bash
# ä½¿ç”¨å¿«é€Ÿæ£€æµ‹æ¨¡å¼ï¼ˆå‡å°‘ç›‘æ§é¢‘ç‡ï¼‰
python train_optimized.py --fast_detection

# å®Œå…¨ç¦ç”¨åéªŒå¡Œç¼©ç›‘æ§ä»¥è·å¾—æœ€å¤§æ€§èƒ½
python train_optimized.py --disable_metrics_monitoring
```

### 4. å†…å­˜ä½¿ç”¨ä¼˜åŒ–

#### âœ… å·²å®Œæˆ
- **åŠ¨æ€å¡«å……**ï¼šå‡å°‘å†…å­˜ä½¿ç”¨
- **åºåˆ—é•¿åº¦é™åˆ¶**ï¼šå¯é…ç½®çš„æœ€å¤§åºåˆ—é•¿åº¦
- **å‡å°‘æ£€æŸ¥ç‚¹ä¿å­˜**ï¼šä»3ä¸ªå‡å°‘åˆ°2ä¸ª
- **ä¼˜åŒ–æ‰¹å¤„ç†å¤§å°**ï¼šé»˜è®¤å¢åŠ åˆ°4

#### ä½¿ç”¨ç¤ºä¾‹
```bash
# ä½¿ç”¨åŠ¨æ€å¡«å……ä»¥å‡å°‘å†…å­˜ä½¿ç”¨
python train_optimized.py --use_dynamic_padding
```

## ğŸ¯ ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹ï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨æ¨èçš„å¿«é€Ÿé…ç½®
python train_optimized.py \
    --batch_size 4 \
    --num_workers 8 \
    --pin_memory \
    --gradient_accumulation_steps 2 \
    --max_sequence_length 1000 \
    --precision 16-mixed \
    --fast_detection
```

### æœ€å¤§æ€§èƒ½é…ç½®ï¼ˆæ— ç›‘æ§ï¼‰

```bash
# ä½¿ç”¨æœ€å¤§æ€§èƒ½é…ç½®ï¼ˆæ— ç›‘æ§ï¼‰
python train_optimized.py \
    --batch_size 4 \
    --num_workers 8 \
    --pin_memory \
    --gradient_accumulation_steps 2 \
    --max_sequence_length 1000 \
    --precision 16-mixed \
    --disable_metrics_monitoring \
    --compile_model
```

### å†…å­˜å—é™é…ç½®

```bash
# ä½¿ç”¨å†…å­˜é«˜æ•ˆé…ç½®
python train_optimized.py \
    --batch_size 2 \
    --num_workers 4 \
    --max_sequence_length 500 \
    --precision 16-mixed \
    --fast_detection
```

### è°ƒè¯•é…ç½®

```bash
# è°ƒè¯•é…ç½®
python train_optimized.py \
    --batch_size 1 \
    --num_workers 2 \
    --max_sequence_length 100 \
    --precision 32 \
    --fast_detection
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### æµ‹è¯•ç¯å¢ƒ
- GPU: NVIDIA A100/V100
- CPU: 8+ cores
- RAM: 32GB+
- Storage: SSD

### é¢„æœŸæ€§èƒ½æå‡

| ä¼˜åŒ–æªæ–½ | é¢„æœŸé€Ÿåº¦æå‡ | å†…å­˜ä½¿ç”¨å˜åŒ– |
|---------|-------------|-------------|
| å¢åŠ æ‰¹å¤„ç†å¤§å° (1â†’4) | 30-50% | +50% |
| å¢åŠ å·¥ä½œè¿›ç¨‹æ•° (2â†’8) | 20-30% | +10% |
| æ··åˆç²¾åº¦è®­ç»ƒ | 20-40% | -30% |
| æ¢¯åº¦ç´¯ç§¯ | 10-20% | æ— å˜åŒ– |
| æ¨¡å‹ç¼–è¯‘ | 10-25% | æ— å˜åŒ– |
| å‡å°‘ç›‘æ§é¢‘ç‡ | 5-15% | -10% |
| é™åˆ¶åºåˆ—é•¿åº¦ | 20-40% | -40% |

### ç»¼åˆä¼˜åŒ–æ•ˆæœ
ä½¿ç”¨æ‰€æœ‰ä¼˜åŒ–æªæ–½åï¼Œé¢„æœŸå¯ä»¥è·å¾— **2-3å€** çš„è®­ç»ƒé€Ÿåº¦æå‡ã€‚

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å†…å­˜ä¸è¶³
```bash
# å‡å°‘æ‰¹å¤„ç†å¤§å°
python train_optimized.py --batch_size 2

# å‡å°‘åºåˆ—é•¿åº¦
python train_optimized.py --max_sequence_length 500

# å‡å°‘å·¥ä½œè¿›ç¨‹æ•°
python train_optimized.py --num_workers 4
```

#### 2. æ•°æ®åŠ è½½ç“¶é¢ˆ
```bash
# å¢åŠ å·¥ä½œè¿›ç¨‹æ•°
python train_optimized.py --num_workers 12

# å¯ç”¨pin_memory
python train_optimized.py --pin_memory
```

#### 3. GPUåˆ©ç”¨ç‡ä½
```bash
# å¢åŠ æ‰¹å¤„ç†å¤§å°
python train_optimized.py --batch_size 8

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
python train_optimized.py --gradient_accumulation_steps 4
```

### ç›‘æ§å’Œè°ƒè¯•

#### 1. æ£€æŸ¥GPUåˆ©ç”¨ç‡
```bash
nvidia-smi -l 1
```

#### 2. æ£€æŸ¥CPUå’Œå†…å­˜ä½¿ç”¨
```bash
htop
```

#### 3. æ£€æŸ¥æ•°æ®åŠ è½½é€Ÿåº¦
```bash
# åœ¨è®­ç»ƒè„šæœ¬ä¸­æ·»åŠ æ•°æ®åŠ è½½æ—¶é—´ç›‘æ§
```

## ğŸ”§ é«˜çº§æŠ€å·§

### 1. æ•°æ®é¢„å¤„ç†ä¼˜åŒ–
- é¢„è®¡ç®—å’Œç¼“å­˜åµŒå…¥å‘é‡
- ä½¿ç”¨æ›´é«˜æ•ˆçš„æ•°æ®æ ¼å¼ï¼ˆå¦‚Parquetï¼‰
- å®ç°æ•°æ®é¢„å–æœºåˆ¶

### 2. æ¨¡å‹æ¶æ„ä¼˜åŒ–
- ä½¿ç”¨æ›´å°çš„æ¨¡å‹ç»´åº¦
- å‡å°‘transformerå±‚æ•°
- ä½¿ç”¨æ›´é«˜æ•ˆçš„æ³¨æ„åŠ›æœºåˆ¶

### 3. åˆ†å¸ƒå¼è®­ç»ƒ
```bash
# å¤šGPUè®­ç»ƒ
python train_optimized.py --devices 2
```

### 4. æ··åˆç²¾åº¦è®­ç»ƒè°ƒä¼˜
```bash
# ä½¿ç”¨bfloat16ï¼ˆå¦‚æœæ”¯æŒï¼‰
python train_optimized.py --precision bf16-mixed
```

## ğŸ“ å®ç°ç»†èŠ‚

### æ–°å¢æ–‡ä»¶

1. **`train_optimized.py`** - ä¼˜åŒ–ç‰ˆæœ¬çš„è®­ç»ƒè„šæœ¬
   - åŒ…å«æ‰€æœ‰æ€§èƒ½ä¼˜åŒ–æªæ–½
   - æ”¯æŒå¤šç§é…ç½®é€‰é¡¹
   - å‘åå…¼å®¹åŸæœ‰åŠŸèƒ½

### æ›´æ–°çš„æ–‡ä»¶

1. **`dataset.py`** - æ•°æ®åŠ è½½ä¼˜åŒ–
   - å¢åŠ äº†å·¥ä½œè¿›ç¨‹æ•°é…ç½®
   - å¯ç”¨äº†å†…å­˜å›ºå®š
   - æ·»åŠ äº†æŒä¹…åŒ–å·¥ä½œè¿›ç¨‹

### é…ç½®å‚æ•°

#### æ•°æ®åŠ è½½å‚æ•°
- `--batch_size`: æ‰¹å¤„ç†å¤§å°ï¼ˆé»˜è®¤ï¼š4ï¼‰
- `--num_workers`: å·¥ä½œè¿›ç¨‹æ•°ï¼ˆé»˜è®¤ï¼š8ï¼‰
- `--pin_memory`: å¯ç”¨å†…å­˜å›ºå®šï¼ˆé»˜è®¤ï¼šTrueï¼‰
- `--max_sequence_length`: æœ€å¤§åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤ï¼š1000ï¼‰

#### è®­ç»ƒå‚æ•°
- `--precision`: è®­ç»ƒç²¾åº¦ï¼ˆé»˜è®¤ï¼š16-mixedï¼‰
- `--gradient_accumulation_steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•°ï¼ˆé»˜è®¤ï¼š2ï¼‰
- `--compile_model`: å¯ç”¨æ¨¡å‹ç¼–è¯‘ï¼ˆé»˜è®¤ï¼šFalseï¼‰

#### ç›‘æ§å‚æ•°
- `--fast_detection`: å¿«é€Ÿç›‘æ§æ¨¡å¼
- `--disable_metrics_monitoring`: ç¦ç”¨ç›‘æ§

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **ç¡¬ä»¶è¦æ±‚**ï¼šä¼˜åŒ–é…ç½®éœ€è¦è¶³å¤Ÿçš„GPUå†…å­˜å’ŒCPUæ ¸å¿ƒæ•°
2. **æ•°æ®æ ¼å¼**ï¼šç¡®ä¿æ•°æ®æ ¼å¼å…¼å®¹ï¼Œç‰¹åˆ«æ˜¯Parquetæ–‡ä»¶
3. **ç‰ˆæœ¬å…¼å®¹æ€§**ï¼šæŸäº›ä¼˜åŒ–éœ€è¦PyTorch 2.0+
4. **ç›‘æ§å¼€é”€**ï¼šå®Œå…¨ç¦ç”¨ç›‘æ§å¯èƒ½å½±å“æ¨¡å‹è´¨é‡è¯„ä¼°

## ğŸ‰ æ€»ç»“

é€šè¿‡å®æ–½è¿™äº›ä¼˜åŒ–æªæ–½ï¼Œæˆ‘ä»¬æ˜¾è‘—æå‡äº†è®­ç»ƒé€Ÿåº¦ï¼ŒåŒæ—¶ä¿æŒäº†æ¨¡å‹çš„æ€§èƒ½ã€‚å»ºè®®ï¼š

1. **é¦–å…ˆå°è¯•å¿«é€Ÿè®­ç»ƒé…ç½®**ï¼Œè¿™æ˜¯æœ€å¹³è¡¡çš„ä¼˜åŒ–æ–¹æ¡ˆ
2. **æ ¹æ®ç¡¬ä»¶èµ„æºè°ƒæ•´å‚æ•°**ï¼Œç‰¹åˆ«æ˜¯æ‰¹å¤„ç†å¤§å°å’Œå·¥ä½œè¿›ç¨‹æ•°
3. **ç›‘æ§ç³»ç»Ÿèµ„æºä½¿ç”¨**ï¼Œç¡®ä¿æ²¡æœ‰ç“¶é¢ˆ
4. **é€æ­¥åº”ç”¨ä¼˜åŒ–æªæ–½**ï¼Œä»¥ä¾¿è¯†åˆ«å“ªäº›æªæ–½æœ€æœ‰æ•ˆ

è¿™äº›ä¼˜åŒ–æªæ–½å¯ä»¥æ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡ï¼Œç‰¹åˆ«æ˜¯åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šè®­ç»ƒæ—¶ã€‚

### å¿«é€Ÿå‚è€ƒ

```bash
# æœ€å¸¸ç”¨çš„ä¼˜åŒ–é…ç½®
python train_optimized.py \
    --batch_size 4 \
    --num_workers 8 \
    --pin_memory \
    --gradient_accumulation_steps 2 \
    --max_sequence_length 1000 \
    --precision 16-mixed \
    --fast_detection
```

è®°ä½ï¼Œä¼˜åŒ–æ˜¯ä¸€ä¸ªè¿­ä»£è¿‡ç¨‹ï¼Œéœ€è¦æ ¹æ®å…·ä½“çš„ç¡¬ä»¶ç¯å¢ƒå’Œæ•°æ®ç‰¹å¾è¿›è¡Œè°ƒæ•´ã€‚

---

# VAEåéªŒå¡Œç¼©æ£€æµ‹ç³»ç»Ÿå®Œæ•´ä½¿ç”¨æŒ‡å—

## ç³»ç»Ÿæ¦‚è¿°

### è§£å†³çš„é—®é¢˜
æ‚¨çš„è®­ç»ƒæ•°æ®éå¸¸å¤§ï¼Œå®Œæˆä¸€ä¸ªepochéœ€è¦24å°æ—¶ã€‚ä¸ºäº†é¿å…æµªè´¹å¤§é‡è®­ç»ƒæ—¶é—´ï¼Œæœ¬ç³»ç»Ÿèƒ½å¤Ÿåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§å…³é”®çš„åéªŒæŒ‡æ ‡ï¼Œå¸®æ‚¨åŠæ—¶å‘ç°é—®é¢˜å¹¶é‡‡å–æªæ–½ã€‚

### æ ¸å¿ƒç‰¹æ€§
- **æŒ‡æ ‡ç›‘æ§**ï¼šè®­ç»ƒè¿‡ç¨‹ä¸­æŒç»­ç›‘æ§å››ä¸ªå…³é”®åéªŒæŒ‡æ ‡
- **å®šæœŸæ›´æ–°**ï¼šæ¯éš”å‡ ä¸ªstepæ›´æ–°æŒ‡æ ‡æ•°æ®
- **è‡ªåŠ¨ä¿å­˜**ï¼šå®šæœŸä¿å­˜æŒ‡æ ‡å›¾è¡¨
- **å¯è§†åŒ–é¢æ¿**ï¼šå®æ—¶å›¾è¡¨æ˜¾ç¤ºå„é¡¹æŒ‡æ ‡å˜åŒ–
- **æ‰¹é‡è®­ç»ƒ**ï¼šæ”¯æŒå¤šç—…äººæ‰¹é‡è®­ç»ƒï¼Œæ˜¾è‘—æé«˜è®­ç»ƒé€Ÿåº¦

## ç³»ç»Ÿæ¶æ„

### æ ¸å¿ƒæ–‡ä»¶ç»“æ„
```
â”œâ”€â”€ posterior_collapse_detector.py          # åéªŒæŒ‡æ ‡ç›‘æ§å™¨ - Posterior metrics monitor
â”œâ”€â”€ train_optimized.py                      # ä¼˜åŒ–è®­ç»ƒè„šæœ¬ - Optimized training script
â”œâ”€â”€ collapse_visualizer.py                  # å®æ—¶å¯è§†åŒ–å·¥å…· - Real-time visualization
â”œâ”€â”€ analyze_training_curves.py              # è®­ç»ƒæ›²çº¿åˆ†æå·¥å…· - Training curves analysis
â”œâ”€â”€ visualize_model.py                      # æ¨¡å‹å¯è§†åŒ–å·¥å…· - Model visualization
â”œâ”€â”€ model.py                                # æ¨¡å‹å®šä¹‰ (å·²å¢å¼º) - Model definition (enhanced)
â”œâ”€â”€ dataset.py                              # æ•°æ®åŠ è½½å™¨ - Data loader
â”œâ”€â”€ modules.py                              # æ¨¡å‹ç»„ä»¶ - Model modules  
â”œâ”€â”€ config.py                               # é…ç½®æ–‡ä»¶ - Configuration
```

### 1. åéªŒæŒ‡æ ‡ç›‘æ§å™¨ (`posterior_collapse_detector.py`)
```python
# Simple posterior metrics monitoring callback class
class PosteriorMetricsMonitor(Callback):
    def __init__(
        self,
        update_frequency: int = 50,           # Update metrics every N steps
        plot_frequency: int = 500,            # Save plot every N steps
        window_size: int = 100,               # History window size
        
        # Output settings
        log_dir: str = "./posterior_metrics", # Log save directory
        verbose: bool = True,                 # Whether to output information,
    ):
        # Initialize monitoring variables and setup logging
        pass
```

### 2. ä¼˜åŒ–è®­ç»ƒè„šæœ¬ (`train_optimized.py`)
```python
# Optimized training script with integrated metrics monitoring
def setup_metrics_monitor(args):
    """Setup metrics monitor based on training requirements"""
    if args.fast_detection:
        # Fast monitoring mode - more frequent updates
        monitor = PosteriorMetricsMonitor(
            update_frequency=100,          # Update every 100 steps
            plot_frequency=1000,           # Save plot every 1000 steps
            window_size=50,                # History window size
        )
    else:
        # Standard monitoring mode
        monitor = PosteriorMetricsMonitor(
            update_frequency=200,          # Update every 200 steps
            plot_frequency=2000,           # Save plot every 2000 steps
            window_size=50,                # History window size
        )
    return monitor
```

### 3. å®æ—¶å¯è§†åŒ–å·¥å…· (`collapse_visualizer.py`)
```python
# Real-time visualization dashboard for metrics monitoring
class RealTimeCollapseVisualizer:
    def __init__(self, log_dir: str, update_interval: int = 1000):
        # Data storage for monitoring metrics
        self.data = {
            'steps': deque(maxlen=1000),         # Training steps
            'kl_divergence': deque(maxlen=1000), # KL divergence values
            'variance': deque(maxlen=1000),      # Latent variable variances
            'active_ratio': deque(maxlen=1000),  # Active units ratios
            'recon_loss': deque(maxlen=1000),    # Reconstruction losses
            'warnings': [],                      # Warning messages
            'collapse_detected': False,          # Collapse detection flag
        }
```

## ç›‘æ§åŸç†

### ç›‘æ§çš„å››ä¸ªå…³é”®æŒ‡æ ‡

#### 1. KLæ•£åº¦ (KL Divergence)
```python
# Calculate KL divergence between posterior and prior
kl_div = 0.5 * torch.sum(torch.exp(logvar) + mu.pow(2) - 1 - logvar, dim=-1)

# Normal range: > 0.01, Collapse risk: < 0.01
# This metric helps identify if the posterior is collapsing to the prior
```

#### 2. æ½œåœ¨å˜é‡æ–¹å·® (Latent Variable Variance)
```python
# Extract variance from log-variance
var = torch.exp(logvar)
mean_var = var.mean().item()

# Normal range: > 0.1, Collapse risk: < 0.1
# This metric shows how much the latent variables are varying
```

#### 3. æ¿€æ´»å•å…ƒæ¯”ä¾‹ (Active Units Ratio)
```python
# Calculate ratio of active latent dimensions
active_units = (var > 0.01).float().mean().item()

# Normal range: > 0.1, Collapse risk: < 0.1
# This metric indicates how many latent dimensions are being used
```

#### 4. é‡å»ºæŸå¤± (Reconstruction Loss)
```python
# Reconstruction loss from the model
recon_loss = model.reconstruction_loss

# Should decrease over time, stagnation may indicate problems
# This metric shows how well the model is reconstructing the input
```

## ä½¿ç”¨æ–¹æ³•

### å¿«é€Ÿå¼€å§‹

#### 1. åŸºæœ¬è®­ç»ƒï¼ˆæ¨èï¼‰
```bash
# å¯åŠ¨å¸¦æŒ‡æ ‡ç›‘æ§çš„è®­ç»ƒ (æ¨è)
python train_optimized.py --fast_detection

# å¯é€‰ï¼šå¯åŠ¨å®æ—¶ç›‘æ§é¢æ¿
# æ³¨æ„ï¼šmetrics logsç°åœ¨é»˜è®¤ä¿å­˜åœ¨ä¸»æ—¥å¿—ç›®å½•ä¸‹çš„posterior_metricså­ç›®å½•ä¸­
python collapse_visualizer.py --log_dir ./outputs/logs/SeqSetVAE_with_metrics_monitoring/version_X/posterior_metrics
```

#### 2. æ‰¹é‡è®­ç»ƒ
```bash
# ä½¿ç”¨batch_size=1ï¼ˆåŸå§‹æ–¹å¼ï¼‰
python train_optimized.py --batch_size 1

# ä½¿ç”¨batch_size=4è¿›è¡Œæ‰¹é‡è®­ç»ƒ
python train_optimized.py --batch_size 4

# ä½¿ç”¨batch_size=8å¹¶é™åˆ¶åºåˆ—é•¿åº¦
python train_optimized.py --batch_size 8 --max_sequence_length 1000

# å®Œæ•´çš„æ‰¹é‡è®­ç»ƒå‘½ä»¤
python train_optimized.py \
    --batch_size 4 \
    --max_sequence_length 1000 \
    --use_dynamic_padding \
    --devices 2 \
    --max_epochs 10
```

### å‚æ•°è¯´æ˜

#### æ‰¹é‡è®­ç»ƒå‚æ•°
- `--batch_size`: æ‰¹é‡å¤§å°ï¼ˆé»˜è®¤ï¼š4ï¼‰
  - 1ï¼šå•ç—…äººè®­ç»ƒï¼ˆåŸå§‹æ–¹å¼ï¼‰
  - >1ï¼šå¤šç—…äººæ‰¹é‡è®­ç»ƒ
  
- `--max_sequence_length`: æœ€å¤§åºåˆ—é•¿åº¦é™åˆ¶ï¼ˆé»˜è®¤ï¼š1000ï¼‰
  - Noneï¼šä¸é™åˆ¶åºåˆ—é•¿åº¦
  - æ•´æ•°ï¼šæˆªæ–­è¶…è¿‡æ­¤é•¿åº¦çš„åºåˆ—
  
- `--use_dynamic_padding`: ä½¿ç”¨åŠ¨æ€paddingï¼ˆé»˜è®¤ï¼šTrueï¼‰
  - è‡ªåŠ¨å¤„ç†ä¸åŒé•¿åº¦çš„åºåˆ—
  - ä½¿ç”¨padding maskå¿½ç•¥å¡«å……ä½ç½®

#### ç›‘æ§å‚æ•°
- `--fast_detection`: å¿«é€Ÿç›‘æ§æ¨¡å¼
  - æ›´é¢‘ç¹çš„æ›´æ–°ï¼ˆæ¯100æ­¥ï¼‰
  - æ›´é¢‘ç¹çš„å›¾è¡¨ä¿å­˜ï¼ˆæ¯1000æ­¥ï¼‰
  - é€‚åˆéœ€è¦æ›´è¯¦ç»†ç›‘æ§çš„æƒ…å†µ

- `--disable_metrics_monitoring`: ç¦ç”¨æŒ‡æ ‡ç›‘æ§
  - å®Œå…¨å…³é—­æŒ‡æ ‡ç›‘æ§åŠŸèƒ½
  - é€‚åˆåªéœ€è¦åŸºæœ¬è®­ç»ƒçš„æƒ…å†µ

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 1. æ‰¹é‡å¤§å°é€‰æ‹©
- å°æ‰¹é‡ï¼ˆ2-4ï¼‰ï¼šé€‚åˆå†…å­˜å—é™çš„æƒ…å†µ
- ä¸­ç­‰æ‰¹é‡ï¼ˆ4-8ï¼‰ï¼šå¹³è¡¡é€Ÿåº¦å’Œå†…å­˜ä½¿ç”¨
- å¤§æ‰¹é‡ï¼ˆ8-16ï¼‰ï¼šé€‚åˆGPUå†…å­˜å……è¶³çš„æƒ…å†µ

#### 2. åºåˆ—é•¿åº¦é™åˆ¶
- æ— é™åˆ¶ï¼šä¿æŒæ‰€æœ‰æ•°æ®ï¼Œä½†å¯èƒ½å†…å­˜ä½¿ç”¨è¾ƒé«˜
- 1000-2000ï¼šé€‚åˆå¤§å¤šæ•°æƒ…å†µ
- 500-1000ï¼šé€‚åˆå†…å­˜å—é™çš„æƒ…å†µ

#### 3. GPUä½¿ç”¨
- å•GPUï¼šbatch_sizeå»ºè®®4-8
- å¤šGPUï¼šå¯ä»¥å¢åŠ batch_size

## å¯è§†åŒ–ä¸åˆ†æ

### 1. è®­ç»ƒæ›²çº¿åˆ†æ (`analyze_training_curves.py`)
ä»TensorBoardæ—¥å¿—ä¸­æå–å¹¶å¯è§†åŒ–è®­ç»ƒæŒ‡æ ‡ã€‚

```bash
# åŸºæœ¬ç”¨æ³•
python analyze_training_curves.py --log_dir /path/to/tensorboard/logs --save_dir ./training_analysis

# ç¤ºä¾‹
python analyze_training_curves.py \
    --log_dir /home/sunx/data/aiiih/projects/sunx/projects/TEEMR/PT/outputs/logs/SeqSetVAE_with_metrics_monitoring/version_0 \
    --save_dir ./my_training_analysis
```

**ç”Ÿæˆçš„æ–‡ä»¶ï¼š**
- `loss_curves.png` - å„ç§æŸå¤±å‡½æ•°çš„è®­ç»ƒæ›²çº¿
- `performance_metrics.png` - AUCã€AUPRCã€å‡†ç¡®ç‡æ›²çº¿
- `training_dynamics.png` - Î²é€€ç«ã€æŸå¤±æƒé‡ã€KL-é‡å»ºæƒè¡¡
- `collapse_analysis.txt` - åéªŒå¡Œç¼©åˆ†ææ€»ç»“

### 2. æ¨¡å‹éšç©ºé—´å¯è§†åŒ– (`visualize_model.py`)
åˆ†æè®­ç»ƒå¥½çš„æ¨¡å‹çš„éšç©ºé—´è¡¨ç¤ºå’Œé‡å»ºè´¨é‡ã€‚

```bash
# åŸºæœ¬ç”¨æ³•
python visualize_model.py --checkpoint /path/to/model.ckpt --save_dir ./visualizations

# å®Œæ•´ç¤ºä¾‹
python visualize_model.py \
    --checkpoint /home/sunx/data/aiiih/projects/sunx/projects/TEEMR/PT/outputs/checkpoints/last.ckpt \
    --data_dir /home/sunx/data/aiiih/data/mimic/processed/patient_ehr \
    --params_map_path /home/sunx/data/aiiih/data/mimic/processed/stats.csv \
    --label_path /home/sunx/data/aiiih/data/mimic/processed/oc.csv \
    --save_dir ./model_visualizations \
    --max_batches 20 \
    --batch_size 32
```

**ç”Ÿæˆçš„æ–‡ä»¶ï¼š**
- `posterior_collapse_analysis.png` - åéªŒå¡Œç¼©è¯¦ç»†åˆ†æ
- `latent_space_umap.png` - éšç©ºé—´UMAPå¯è§†åŒ–
- `reconstruction_errors.png` - é‡å»ºè¯¯å·®åˆ†å¸ƒ
- `latent_correlation.png` - éšå˜é‡ç›¸å…³æ€§çƒ­å›¾

## å…³é”®æŒ‡æ ‡è§£è¯»

### æŸå¤±å‡½æ•°æŒ‡æ ‡
1. **KLæ•£åº¦ (`train_kl_step`/`val_kl`)**
   - æ­£å¸¸èŒƒå›´ï¼š0.1-10
   - < 0.01ï¼šå¯èƒ½å‘ç”ŸåéªŒå¡Œç¼©
   - > 100ï¼šå¯èƒ½è¿‡åº¦æ­£åˆ™åŒ–

2. **é‡å»ºæŸå¤± (`train_recon_step`/`val_recon`)**
   - åº”è¯¥æŒç»­ä¸‹é™
   - åœæ»å¯èƒ½è¡¨ç¤ºæ¨¡å‹å®¹é‡ä¸è¶³

3. **é¢„æµ‹æŸå¤± (`train_pred_step`/`val_pred`)**
   - åæ˜ ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½
   - ä¸AUCç­‰æŒ‡æ ‡ç›¸å…³

### æ€§èƒ½æŒ‡æ ‡
1. **AUC (Area Under ROC Curve)**
   - 0.5ï¼šéšæœºçŒœæµ‹
   - 0.7-0.8ï¼šè‰¯å¥½
   - > 0.9ï¼šä¼˜ç§€

2. **AUPRC (Area Under PR Curve)**
   - å¯¹ä¸å¹³è¡¡æ•°æ®é›†æ›´æ•æ„Ÿ
   - é€šå¸¸ä½äºAUC

3. **å‡†ç¡®ç‡ (`val_accuracy`)**
   - åæ˜ åˆ†ç±»æ€§èƒ½
   - ä¸AUCç›¸å…³ä½†ä¸å®Œå…¨ç›¸åŒ

### è®­ç»ƒåŠ¨æ€
1. **Î²é€€ç«æ›²çº¿**
   - åº”è¯¥ä»0é€æ¸å¢åŠ åˆ°max_beta
   - è¿‡å¿«å¢åŠ å¯èƒ½å¯¼è‡´è®­ç»ƒä¸ç¨³å®š

2. **æŸå¤±æƒé‡åˆ†å¸ƒ**
   - æ˜¾ç¤ºå„æŸå¤±é¡¹çš„ç›¸å¯¹é‡è¦æ€§
   - å¸®åŠ©ç†è§£æ¨¡å‹ä¼˜åŒ–é‡ç‚¹

## é—®é¢˜è¯Šæ–­ä¸è§£å†³

### 1. åéªŒå¡Œç¼©
**ç—‡çŠ¶ï¼š**
- KLæ•£åº¦ < 0.01
- å¤§é‡éšç»´åº¦å¤±æ´»
- æ€§èƒ½åœæ»

**è§£å†³æ–¹æ¡ˆï¼š**
- é™ä½Î²å€¼
- ä½¿ç”¨free bits
- å¢åŠ warmupæ­¥æ•°

### 2. è¿‡æ‹Ÿåˆ
**ç—‡çŠ¶ï¼š**
- è®­ç»ƒæŸå¤±ä¸‹é™ï¼ŒéªŒè¯æŸå¤±ä¸Šå‡
- éªŒè¯æ€§èƒ½ä¸‹é™

**è§£å†³æ–¹æ¡ˆï¼š**
- å¢åŠ æ­£åˆ™åŒ–
- å‡å°‘æ¨¡å‹å®¹é‡
- æ—©åœè®­ç»ƒ

### 3. è®­ç»ƒä¸ç¨³å®š
**ç—‡çŠ¶ï¼š**
- æŸå¤±å‰§çƒˆæ³¢åŠ¨
- æ¢¯åº¦çˆ†ç‚¸æˆ–æ¶ˆå¤±

**è§£å†³æ–¹æ¡ˆï¼š**
- è°ƒæ•´å­¦ä¹ ç‡
- ä½¿ç”¨æ¢¯åº¦è£å‰ª
- æ£€æŸ¥æ•°æ®é¢„å¤„ç†

## æ€§èƒ½å¯¹æ¯”

### è®­ç»ƒé€Ÿåº¦

| æ‰¹é‡å¤§å° | ç›¸å¯¹é€Ÿåº¦ | å†…å­˜ä½¿ç”¨ | é€‚ç”¨åœºæ™¯ |
|---------|---------|---------|---------|
| 1       | 1.0x    | ä½      | è°ƒè¯•ã€å°æ•°æ®é›† |
| 4       | 2.5x    | ä¸­ç­‰    | ä¸€èˆ¬è®­ç»ƒ |
| 8       | 4.0x    | é«˜      | å¿«é€Ÿè®­ç»ƒ |
| 16      | 6.0x    | å¾ˆé«˜    | å¤§è§„æ¨¡è®­ç»ƒ |

### å†…å­˜ä½¿ç”¨ç¤ºä¾‹

```python
# å†…å­˜ä½¿ç”¨ä¼°ç®—ï¼ˆåŸºäºå®é™…æµ‹è¯•ï¼‰
batch_size_1_memory = 2.5  # GB
batch_size_4_memory = 6.0  # GB
batch_size_8_memory = 12.0 # GB
```

## æŠ€æœ¯å®ç°ç»†èŠ‚

### 1. åŠ¨æ€Paddingç­–ç•¥

```python
def _dynamic_collate_fn(self, batch):
    # è®¡ç®—æœ€å¤§åºåˆ—é•¿åº¦
    max_events = max(len(df) for df, _ in batch)
    
    # åˆ›å»ºpadded tensors
    padded_vars = torch.zeros(batch_size, max_events, embed_dim)
    padding_mask = torch.ones(batch_size, max_events, dtype=torch.bool)
    
    # å¡«å……å®é™…æ•°æ®
    for i, (df, _) in enumerate(batch):
        seq_len = len(df)
        padded_vars[i, :seq_len] = process_data(df)
        padding_mask[i, :seq_len] = False  # Falseè¡¨ç¤ºçœŸå®æ•°æ®
```

### 2. æ‰¹é‡å¤„ç†æµç¨‹

1. **æ•°æ®åŠ è½½**ï¼šå¹¶è¡ŒåŠ è½½å¤šä¸ªç—…äººçš„æ•°æ®
2. **åŠ¨æ€Padding**ï¼šæ ¹æ®æ‰¹æ¬¡ä¸­æœ€é•¿åºåˆ—è¿›è¡Œpadding
3. **å‰å‘ä¼ æ’­**ï¼šæ‰¹é‡å¤„ç†å¤šä¸ªç—…äººæ•°æ®
4. **æŸå¤±è®¡ç®—**ï¼šè€ƒè™‘padding maskçš„æŸå¤±è®¡ç®—
5. **åå‘ä¼ æ’­**ï¼šæ‰¹é‡æ¢¯åº¦æ›´æ–°

### 3. ç›‘æ§å™¨é›†æˆ

```python
# åœ¨è®­ç»ƒè„šæœ¬ä¸­é›†æˆç›‘æ§å™¨
monitor = PosteriorMetricsMonitor(
    update_frequency=100,
    plot_frequency=1000,
    window_size=50,
    log_dir=os.path.join(logger.log_dir, "posterior_metrics")
)

# æ·»åŠ åˆ°è®­ç»ƒå™¨
trainer = pl.Trainer(
    callbacks=[monitor],
    # ... å…¶ä»–å‚æ•°
)
```

## æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
   - å‡å°‘batch_size
   - é™åˆ¶åºåˆ—é•¿åº¦
   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯

2. **ç›‘æ§å™¨ä¸å·¥ä½œ**
   - æ£€æŸ¥æ—¥å¿—ç›®å½•æƒé™
   - ç¡®è®¤æ¨¡å‹è¾“å‡ºæ ¼å¼
   - éªŒè¯æ›´æ–°é¢‘ç‡è®¾ç½®

3. **å¯è§†åŒ–é—®é¢˜**
   - æ£€æŸ¥matplotlibåç«¯
   - ç¡®è®¤ä¸­æ–‡å­—ä½“æ”¯æŒ
   - éªŒè¯æ•°æ®æ ¼å¼

### è°ƒè¯•æŠ€å·§

1. **å¯ç”¨è¯¦ç»†æ—¥å¿—**
   ```bash
   python train_optimized.py --verbose
   ```

2. **æ£€æŸ¥ç›‘æ§å™¨çŠ¶æ€**
   ```python
   # åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æ£€æŸ¥ç›‘æ§å™¨çŠ¶æ€
   print(f"Steps monitored: {len(monitor.steps_history)}")
   print(f"Current step: {monitor.global_step}")
   ```

3. **æ‰‹åŠ¨åˆ†ææ—¥å¿—**
   ```bash
   # æŸ¥çœ‹ç›‘æ§å™¨æ—¥å¿—
   ls ./posterior_metrics/
   ```

## æ€»ç»“

æœ¬ç³»ç»Ÿæä¾›äº†å®Œæ•´çš„VAEåéªŒæŒ‡æ ‡ç›‘æ§è§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬ï¼š

1. **æŒ‡æ ‡ç›‘æ§**ï¼šåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ç›‘æ§å››ä¸ªå…³é”®åéªŒæŒ‡æ ‡
2. **æ‰¹é‡è®­ç»ƒ**ï¼šæ˜¾è‘—æé«˜è®­ç»ƒæ•ˆç‡
3. **å¯è§†åŒ–åˆ†æ**ï¼šå…¨é¢çš„è®­ç»ƒè¿‡ç¨‹åˆ†æ
4. **æ™ºèƒ½ç›‘æ§**ï¼šè‡ªåŠ¨åŒ–çš„ç›‘æ§å’Œå›¾è¡¨ä¿å­˜ç³»ç»Ÿ

é€šè¿‡ä½¿ç”¨æœ¬ç³»ç»Ÿï¼Œæ‚¨å¯ä»¥ï¼š
- åŠæ—¶å‘ç°é—®é¢˜ï¼ˆé€šè¿‡ç›‘æ§å…³é”®æŒ‡æ ‡ï¼‰
- æé«˜è®­ç»ƒæ•ˆç‡ï¼ˆæ‰¹é‡è®­ç»ƒï¼‰
- è·å¾—æ›´å¥½çš„æ¨¡å‹æ€§èƒ½ï¼ˆåŠæ—¶å‘ç°é—®é¢˜å¹¶è°ƒæ•´ï¼‰
- æ·±å…¥äº†è§£æ¨¡å‹è¡Œä¸ºï¼ˆå¯è§†åŒ–åˆ†æï¼‰

å»ºè®®ä»å¿«é€Ÿç›‘æ§æ¨¡å¼å¼€å§‹ä½¿ç”¨ï¼Œæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´å‚æ•°å’Œæ‰¹é‡å¤§å°ã€‚

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestæ¥æ”¹è¿›é¡¹ç›®ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ï¼Œè¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚