# Recon Eval JSON Visualization Guide

This guide helps you visualize and analyze the JSON files generated by `evaluate_reconstruction.py`.

## 🚀 Quick Start

### Option 1: Simple Text-Based Analysis (No Dependencies)
```bash
# Analyze a specific JSON file
python3 simple_json_viewer.py --json_file path/to/reconstruction_eval_20241208_143022.json

# Auto-discover and analyze JSON files in current directory
python3 simple_json_viewer.py

# Compare multiple files
python3 simple_json_viewer.py --compare

# Export data as CSV for Excel analysis
python3 simple_json_viewer.py --export_csv --export_detailed_csv
```

### Option 2: Rich Visual Dashboard (Requires Dependencies)
```bash
# Install dependencies (in virtual environment recommended)
pip install -r requirements_viz.txt

# Create comprehensive dashboard
python3 recon_eval_visualizer.py --json_file path/to/file.json

# Compare multiple files with charts
python3 recon_eval_visualizer.py --json_dir ./recon_eval --compare

# Save visualizations without showing
python3 recon_eval_visualizer.py --json_file file.json --no_show --export_report
```

## 📊 What You Get

### Simple Text Viewer (`simple_json_viewer.py`)
- ✅ **No dependencies required** - works with standard Python
- 📋 Formatted summary with quality indicators
- 📈 Per-sample analysis and trends
- 🔄 Multi-file comparison tables
- 📄 CSV export for external analysis

**Sample Output:**
```
🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹 SUMMARY 🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹🔹

📊 **Evaluation Overview**
   Number of samples analyzed: 5

📏 **Distance Quality** (Lower = Better)
   L2 Mean Distance:     0.4500 🟡 Good
   L2 Median Distance:   0.3800 🟡 Good
   L2 95th Percentile:   0.8500 🟡 Good
   Chamfer L2 Distance:  0.2800 🟡 Good

🧭 **Directional Quality** (Higher = Better)
   Cosine Similarity:    0.7800 🟡 Good

🎯 **Overall Assessment**
   🟡 **GOOD** - Satisfactory reconstruction quality
   Quality Score: 3.0/4.0
```

### Rich Visual Dashboard (`recon_eval_visualizer.py`)
- 📊 **Interactive dashboards** with multiple chart types
- 🎯 **Radar charts** for quality assessment
- 📈 **Per-sample trend analysis** with line plots
- 🔥 **Heatmaps** for coverage analysis
- 🔄 **Multi-file comparison** with correlation matrices
- 💾 **Export capabilities** (PNG, PDF, Markdown reports)

## 📁 File Structure Understanding

The JSON files contain:
```json
{
  "summary": {
    "num_samples": 5,
    "nn_l2_mean": 0.45,           // Average L2 distance (lower = better)
    "dir_cosine_mean": 0.78,      // Directional similarity (higher = better)
    "chamfer_l2_mean": 0.28,      // Symmetric distance metric
    "mag_corr": 0.75,             // Magnitude correlation (higher = better)
    "scale_ratio": 1.15,          // Scale preservation (closer to 1.0 = better)
    "coverage@0.5": 0.78,         // % points within distance 0.5
    "coverage@1.0": 0.92,         // % points within distance 1.0
    ...
  },
  "details": [
    {
      "sample_index": 0,
      "global": { /* same metrics as summary for this sample */ },
      "per_set": [ /* metrics for each set within the sample */ ]
    },
    ...
  ]
}
```

## 🎯 Key Metrics Explained

| Metric | Description | Good Range | Interpretation |
|--------|-------------|------------|----------------|
| `nn_l2_mean` | Average nearest neighbor L2 distance | < 0.5 | How close reconstructed points are to originals |
| `dir_cosine_mean` | Average cosine similarity | > 0.8 | How well directions are preserved |
| `chamfer_l2_mean` | Symmetric Chamfer distance | < 0.5 | Overall reconstruction quality |
| `mag_corr` | Magnitude correlation | > 0.7 | How well magnitudes are preserved |
| `scale_ratio` | Reconstruction/original scale ratio | ~1.0 | Scale preservation (1.0 = perfect) |
| `coverage@X` | % points within distance X | > 0.8 | Reconstruction coverage quality |

## 🛠️ Advanced Usage

### Batch Analysis
```bash
# Analyze all JSON files in a directory
python3 simple_json_viewer.py --json_dir ./results --compare --export_csv

# Create visualizations for all files
for file in ./recon_eval/*.json; do
    python3 recon_eval_visualizer.py --json_file "$file" --no_show
done
```

### Integration with Evaluation Pipeline
```bash
# Run evaluation and immediately visualize
python3 evaluate_reconstruction.py --checkpoint model.pt --data_dir ./data \
    --params_map_path params.json --label_path labels.json --num_samples 10

# Then visualize the latest result
python3 simple_json_viewer.py --json_dir ./recon_eval
```

## 🐛 Troubleshooting

### No JSON Files Found
- Make sure you've run `evaluate_reconstruction.py` first
- Check the `--save_dir` argument used in evaluation
- Use `--json_dir` to specify the correct directory

### Dependencies Issues
- Use `simple_json_viewer.py` for dependency-free analysis
- For rich visualizations, create a virtual environment:
  ```bash
  python3 -m venv viz_env
  source viz_env/bin/activate
  pip install -r requirements_viz.txt
  ```

### Performance Issues
- For large files, use `--no_show` to save without displaying
- Export to CSV for analysis in external tools
- Use sampling if dealing with many files

## 📈 Interpretation Guide

### Quality Assessment
- **🟢 Excellent**: L2 < 0.2, Cosine > 0.9, Coverage@0.5 > 0.9
- **🟡 Good**: L2 < 0.5, Cosine > 0.8, Coverage@0.5 > 0.7  
- **🟠 Fair**: L2 < 1.0, Cosine > 0.6, Coverage@0.5 > 0.5
- **🔴 Poor**: Above thresholds indicate reconstruction issues

### Common Issues
- **High L2 distances**: Poor point-wise reconstruction
- **Low cosine similarity**: Direction/orientation problems
- **Scale ratio ≠ 1.0**: Magnitude scaling issues
- **Low coverage**: Missing or displaced reconstructions
- **Low magnitude correlation**: Inconsistent magnitude preservation

## 🔧 Customization

Both tools are easily customizable:
- Modify quality thresholds in `_quality_indicator()` methods
- Add new metrics visualization in the dashboard
- Customize color schemes and plot styles
- Add domain-specific analysis functions