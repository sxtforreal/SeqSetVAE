#!/usr/bin/env python3
"""
æµ‹è¯•è‡ªé€‚åº”è®¾å¤‡é€‰æ‹©é…ç½®é€»è¾‘ï¼ˆä¸ä¾èµ–PyTorchï¼‰
"""

import os
import sys

def mock_torch_cuda_available():
    """æ¨¡æ‹Ÿtorch.cuda.is_available()"""
    # æ£€æŸ¥ç¯å¢ƒå˜é‡æˆ–ç³»ç»Ÿä¿¡æ¯æ¥åˆ¤æ–­æ˜¯å¦æœ‰GPU
    if os.environ.get('CUDA_VISIBLE_DEVICES'):
        return True
    
    # æ£€æŸ¥æ˜¯å¦æœ‰NVIDIA GPU
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        return result.returncode == 0
    except:
        return False

def mock_torch_cuda_device_count():
    """æ¨¡æ‹Ÿtorch.cuda.device_count()"""
    if not mock_torch_cuda_available():
        return 0
    
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--list-gpus'], capture_output=True, text=True)
        if result.returncode == 0:
            return len(result.stdout.strip().split('\n'))
        return 1  # å‡è®¾è‡³å°‘æœ‰ä¸€ä¸ªGPU
    except:
        return 1

def mock_torch_cuda_get_device_name(device_id):
    """æ¨¡æ‹Ÿtorch.cuda.get_device_name()"""
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--query-gpu=name', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            gpus = result.stdout.strip().split('\n')
            if device_id < len(gpus):
                return gpus[device_id]
        return "Unknown GPU"
    except:
        return "Unknown GPU"

def mock_torch_cuda_get_device_properties(device_id):
    """æ¨¡æ‹Ÿtorch.cuda.get_device_properties()"""
    class MockProperties:
        def __init__(self, total_memory):
            self.total_memory = total_memory
    
    try:
        import subprocess
        result = subprocess.run(['nvidia-smi', '--query-gpu=memory.total', '--format=csv,noheader,nounits'], 
                              capture_output=True, text=True)
        if result.returncode == 0:
            memories = result.stdout.strip().split('\n')
            if device_id < len(memories):
                # è½¬æ¢ä¸ºå­—èŠ‚ (MB to bytes)
                memory_mb = int(memories[device_id])
                memory_bytes = memory_mb * 1024 * 1024
                return MockProperties(memory_bytes)
        return MockProperties(8 * 1024 * 1024 * 1024)  # é»˜è®¤8GB
    except:
        return MockProperties(8 * 1024 * 1024 * 1024)  # é»˜è®¤8GB

def get_optimal_device_config():
    """
    æ™ºèƒ½æ£€æµ‹å¹¶è¿”å›æœ€ä¼˜çš„è®¾å¤‡é…ç½®ï¼ˆæ¨¡æ‹Ÿç‰ˆæœ¬ï¼‰
    è‡ªé€‚åº”é€‰æ‹©ï¼šå¦‚æœæœ‰GPUå°±ä½¿ç”¨GPUï¼Œå¦åˆ™ä½¿ç”¨CPU
    """
    # æ£€æŸ¥CUDAæ˜¯å¦å¯ç”¨
    cuda_available = mock_torch_cuda_available()
    
    if cuda_available:
        # è·å–GPUä¿¡æ¯
        gpu_count = mock_torch_cuda_device_count()
        gpu_name = mock_torch_cuda_get_device_name(0) if gpu_count > 0 else "Unknown"
        gpu_memory = mock_torch_cuda_get_device_properties(0).total_memory / 1024**3 if gpu_count > 0 else 0
        
        print(f"ğŸš€ GPU detected: {gpu_name} ({gpu_memory:.1f}GB)")
        
        # æ ¹æ®GPUå†…å­˜è°ƒæ•´é…ç½®
        if gpu_memory >= 16:  # 16GB+ GPU
            devices = min(gpu_count, 2)  # æœ€å¤šä½¿ç”¨2ä¸ªGPU
            precision = "16-mixed"
            batch_size_recommendation = 8
        elif gpu_memory >= 8:  # 8-16GB GPU
            devices = 1
            precision = "16-mixed"
            batch_size_recommendation = 4
        else:  # å°äº8GB GPU
            devices = 1
            precision = "32"  # ä½¿ç”¨32ä½ç²¾åº¦é¿å…å†…å­˜ä¸è¶³
            batch_size_recommendation = 2
            
        accelerator = "gpu"
        device = "cuda"
        
        print(f"   - Using {devices} GPU(s)")
        print(f"   - Precision: {precision}")
        print(f"   - Recommended batch size: {batch_size_recommendation}")
        
    else:
        # CPUé…ç½®
        import multiprocessing
        cpu_count = multiprocessing.cpu_count()
        
        print(f"ğŸ’» CPU detected: {cpu_count} cores")
        
        devices = 1
        accelerator = "cpu"
        precision = "32"  # CPUè®­ç»ƒä½¿ç”¨32ä½ç²¾åº¦
        device = "cpu"
        batch_size_recommendation = 1
        
        print(f"   - Using CPU training")
        print(f"   - Precision: {precision}")
        print(f"   - Recommended batch size: {batch_size_recommendation}")
    
    return {
        'device': device,
        'accelerator': accelerator,
        'devices': devices,
        'precision': precision,
        'batch_size_recommendation': batch_size_recommendation,
        'cuda_available': cuda_available
    }

def test_adaptive_config():
    """æµ‹è¯•è‡ªé€‚åº”é…ç½®"""
    print("ğŸ§ª Testing Adaptive Device Configuration Logic")
    print("=" * 60)
    
    # è·å–é…ç½®
    config = get_optimal_device_config()
    
    print(f"\nğŸ“Š Configuration Results:")
    print(f"  - Device: {config['device']}")
    print(f"  - Accelerator: {config['accelerator']}")
    print(f"  - Devices count: {config['devices']}")
    print(f"  - Precision: {config['precision']}")
    print(f"  - CUDA available: {config['cuda_available']}")
    print(f"  - Recommended batch size: {config['batch_size_recommendation']}")
    
    # éªŒè¯é…ç½®é€»è¾‘
    print(f"\nâœ… Configuration Validation:")
    
    if config['cuda_available']:
        if config['accelerator'] == 'gpu' and config['device'] == 'cuda':
            print(f"  âœ… GPU configuration is correct")
        else:
            print(f"  âŒ GPU configuration is incorrect")
            return False
            
        if config['precision'] in ['16-mixed', '32']:
            print(f"  âœ… GPU precision setting is valid")
        else:
            print(f"  âŒ GPU precision setting is invalid")
            return False
    else:
        if config['accelerator'] == 'cpu' and config['device'] == 'cpu':
            print(f"  âœ… CPU configuration is correct")
        else:
            print(f"  âŒ CPU configuration is incorrect")
            return False
            
        if config['precision'] == '32':
            print(f"  âœ… CPU precision setting is valid")
        else:
            print(f"  âŒ CPU precision setting is invalid")
            return False
    
    print(f"\nğŸ‰ All configuration tests passed!")
    return True

if __name__ == "__main__":
    print("ğŸš€ Starting Adaptive Configuration Logic Tests")
    
    # è¿è¡Œé…ç½®æµ‹è¯•
    if test_adaptive_config():
        print(f"\nğŸ‰ All adaptive configuration logic tests completed successfully!")
    else:
        print(f"\nâŒ Configuration tests failed!")
        sys.exit(1)