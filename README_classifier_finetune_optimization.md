# 分类头微调优化指南

## 问题分析

你的训练损失图显示了一个典型的**过拟合**和**学习率过高**的问题：

1. **训练损失在后期上升**：这表明分类头在训练集上过拟合
2. **验证性能可能不稳定**：高学习率导致模型在最优解附近震荡
3. **参数冻结确实有效**：但分类头本身需要更精细的调优

## 主要修改

### 1. 学习率优化
- **原始学习率**: `1e-3` (0.001) - 过高
- **优化后学习率**: `5e-4` (0.0005) - 更适合分类头微调
- **原因**: 分类头是一个相对简单的网络，高学习率容易导致过拟合

### 2. 权重衰减调整
- **原始权重衰减**: `0.01` - 过高
- **优化后权重衰减**: `0.001` - 更适合分类头
- **原因**: 过高的权重衰减会过度限制模型的学习能力

### 3. 学习率调度器优化
- **原始patience**: 5 epochs - 响应太慢
- **优化后patience**: 3 epochs - 更及时的学习率调整
- **调度因子**: 从0.6改为0.7，更温和的学习率衰减

### 4. 梯度裁剪优化
- **原始梯度裁剪**: 0.1 - 过高
- **优化后梯度裁剪**: 0.05 - 更适合分类头微调
- **原因**: 分类头参数较少，不需要太强的梯度裁剪

### 5. Focal Loss参数调整
- **Gamma值**: 从3.0降低到2.5
- **原因**: 降低gamma值可以减少对困难样本的过度关注，提高训练稳定性

## 使用方法

### 方法1: 使用优化后的脚本
```bash
python run_classifier_finetune_optimized.py
```

### 方法2: 手动指定参数
```bash
python finetune_classifier_head.py \
    --head_lr 5e-4 \
    --max_epochs 50 \
    --batch_size 8
```

### 方法3: 使用配置文件
```bash
# 修改 config_classifier_finetune.py 中的参数
# 然后运行原始脚本
python finetune_classifier_head.py
```

## 预期效果

使用这些优化后，你应该看到：

1. **训练损失更稳定**：减少震荡和上升趋势
2. **收敛更快**：分类头能更快找到最优解
3. **泛化性能更好**：减少过拟合，提高验证集性能
4. **训练更稳定**：减少训练过程中的异常行为

## 进一步调优建议

如果问题仍然存在，可以考虑：

1. **进一步降低学习率**: 尝试 `3e-4` 或 `1e-4`
2. **增加正则化**: 在分类头中添加更多dropout
3. **使用余弦退火调度器**: 替代ReduceLROnPlateau
4. **数据增强**: 增加训练数据的多样性
5. **交叉验证**: 使用k折交叉验证来评估模型稳定性

## 监控指标

训练过程中重点关注：

1. **训练损失趋势**: 应该平稳下降，不应上升
2. **验证AUC**: 应该稳定提升
3. **学习率变化**: 应该根据验证性能自动调整
4. **梯度范数**: 应该保持稳定

## 注意事项

1. **确保参数冻结**: 验证只有分类头参数在更新
2. **检查数据质量**: 确保训练和验证数据分布一致
3. **监控过拟合**: 如果训练损失继续下降但验证性能下降，说明过拟合
4. **保存最佳模型**: 使用验证AUC作为模型选择标准