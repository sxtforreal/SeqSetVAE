#!/usr/bin/env python3
"""
æ€§èƒ½æµ‹è¯•è„šæœ¬
ç”¨äºæ¯”è¾ƒä¸åŒé…ç½®çš„è®­ç»ƒé€Ÿåº¦
"""

import time
import torch
import psutil
import os
import argparse
from datetime import datetime
import subprocess
import json

def get_system_info():
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    info = {
        "cpu_count": psutil.cpu_count(),
        "memory_gb": psutil.virtual_memory().total / (1024**3),
        "gpu_available": torch.cuda.is_available(),
        "gpu_count": torch.cuda.device_count() if torch.cuda.is_available() else 0,
    }
    
    if torch.cuda.is_available():
        info["gpu_name"] = torch.cuda.get_device_name(0)
        info["gpu_memory_gb"] = torch.cuda.get_device_properties(0).total_memory / (1024**3)
    
    return info

def run_training_test(config_name, config_args, duration_minutes=5):
    """è¿è¡Œè®­ç»ƒæµ‹è¯•"""
    print(f"\nğŸ§ª æµ‹è¯•é…ç½®: {config_name}")
    print("=" * 50)
    
    # æ„å»ºå‘½ä»¤
    cmd = ["python", "train_optimized.py"] + config_args + ["--max_epochs", "1"]
    
    print(f"æ‰§è¡Œå‘½ä»¤: {' '.join(cmd)}")
    
    # è®°å½•å¼€å§‹æ—¶é—´
    start_time = time.time()
    start_memory = psutil.virtual_memory().used / (1024**3)
    
    if torch.cuda.is_available():
        torch.cuda.reset_peak_memory_stats()
        start_gpu_memory = torch.cuda.memory_allocated() / (1024**3)
    
    try:
        # è¿è¡Œè®­ç»ƒ
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True
        )
        
        # ç›‘æ§è¿›ç¨‹
        while process.poll() is None:
            elapsed = time.time() - start_time
            if elapsed > duration_minutes * 60:
                print(f"â° æµ‹è¯•æ—¶é—´è¾¾åˆ° {duration_minutes} åˆ†é’Ÿï¼Œåœæ­¢æµ‹è¯•")
                process.terminate()
                break
            
            # æ¯30ç§’è¾“å‡ºä¸€æ¬¡çŠ¶æ€
            if int(elapsed) % 30 == 0 and int(elapsed) > 0:
                current_memory = psutil.virtual_memory().used / (1024**3)
                memory_usage = current_memory - start_memory
                
                status = f"â±ï¸  å·²è¿è¡Œ: {elapsed:.1f}s, å†…å­˜ä½¿ç”¨: +{memory_usage:.1f}GB"
                
                if torch.cuda.is_available():
                    current_gpu_memory = torch.cuda.memory_allocated() / (1024**3)
                    gpu_memory_usage = current_gpu_memory - start_gpu_memory
                    status += f", GPUå†…å­˜: +{gpu_memory_usage:.1f}GB"
                
                print(status)
            
            time.sleep(1)
        
        # è·å–è¾“å‡º
        stdout, stderr = process.communicate()
        
        # è®°å½•ç»“æŸæ—¶é—´
        end_time = time.time()
        total_time = end_time - start_time
        
        # è®¡ç®—å†…å­˜ä½¿ç”¨
        end_memory = psutil.virtual_memory().used / (1024**3)
        memory_usage = end_memory - start_memory
        
        gpu_memory_usage = 0
        if torch.cuda.is_available():
            end_gpu_memory = torch.cuda.memory_allocated() / (1024**3)
            gpu_memory_usage = end_gpu_memory - start_gpu_memory
        
        # è§£æè¾“å‡ºä¸­çš„å…³é”®ä¿¡æ¯
        metrics = {
            "config_name": config_name,
            "total_time": total_time,
            "memory_usage_gb": memory_usage,
            "gpu_memory_usage_gb": gpu_memory_usage,
            "exit_code": process.returncode,
            "stdout": stdout,
            "stderr": stderr
        }
        
        print(f"âœ… æµ‹è¯•å®Œæˆ - æ€»æ—¶é—´: {total_time:.1f}s")
        print(f"   - å†…å­˜ä½¿ç”¨: +{memory_usage:.1f}GB")
        if torch.cuda.is_available():
            print(f"   - GPUå†…å­˜ä½¿ç”¨: +{gpu_memory_usage:.1f}GB")
        
        return metrics
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return {
            "config_name": config_name,
            "error": str(e),
            "total_time": time.time() - start_time
        }

def main():
    parser = argparse.ArgumentParser(description="æ€§èƒ½æµ‹è¯•è„šæœ¬")
    parser.add_argument("--duration", type=int, default=5, help="æ¯ä¸ªæµ‹è¯•çš„æœ€å¤§è¿è¡Œæ—¶é—´ï¼ˆåˆ†é’Ÿï¼‰")
    parser.add_argument("--output", type=str, default="performance_results.json", help="ç»“æœè¾“å‡ºæ–‡ä»¶")
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•")
    print("=" * 60)
    
    # è·å–ç³»ç»Ÿä¿¡æ¯
    system_info = get_system_info()
    print("ğŸ“Š ç³»ç»Ÿä¿¡æ¯:")
    print(f"   - CPUæ ¸å¿ƒæ•°: {system_info['cpu_count']}")
    print(f"   - å†…å­˜: {system_info['memory_gb']:.1f}GB")
    print(f"   - GPUå¯ç”¨: {system_info['gpu_available']}")
    if system_info['gpu_available']:
        print(f"   - GPUæ•°é‡: {system_info['gpu_count']}")
        print(f"   - GPUåç§°: {system_info['gpu_name']}")
        print(f"   - GPUå†…å­˜: {system_info['gpu_memory_gb']:.1f}GB")
    
    # å®šä¹‰æµ‹è¯•é…ç½®
    test_configs = {
        "baseline": {
            "args": ["--batch_size", "1", "--num_workers", "2", "--precision", "32"]
        },
        "optimized_fast": {
            "args": [
                "--batch_size", "4",
                "--num_workers", "8",
                "--pin_memory",
                "--gradient_accumulation_steps", "2",
                "--max_sequence_length", "1000",
                "--precision", "16-mixed",
                "--fast_detection"
            ]
        },
        "optimized_max": {
            "args": [
                "--batch_size", "4",
                "--num_workers", "8",
                "--pin_memory",
                "--gradient_accumulation_steps", "2",
                "--max_sequence_length", "1000",
                "--precision", "16-mixed",
                "--disable_metrics_monitoring",
                "--compile_model"
            ]
        },
        "memory_efficient": {
            "args": [
                "--batch_size", "2",
                "--num_workers", "4",
                "--max_sequence_length", "500",
                "--precision", "16-mixed",
                "--fast_detection"
            ]
        }
    }
    
    # è¿è¡Œæµ‹è¯•
    results = {
        "system_info": system_info,
        "test_time": datetime.now().isoformat(),
        "duration_minutes": args.duration,
        "configs": {}
    }
    
    for config_name, config in test_configs.items():
        print(f"\n{'='*60}")
        metrics = run_training_test(config_name, config["args"], args.duration)
        results["configs"][config_name] = metrics
    
    # ä¿å­˜ç»“æœ
    with open(args.output, 'w') as f:
        json.dump(results, f, indent=2)
    
    # è¾“å‡ºæ€»ç»“
    print(f"\n{'='*60}")
    print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“:")
    print("=" * 60)
    
    baseline_time = results["configs"]["baseline"]["total_time"]
    
    for config_name, metrics in results["configs"].items():
        if "error" not in metrics:
            speedup = baseline_time / metrics["total_time"] if metrics["total_time"] > 0 else 0
            print(f"\n{config_name}:")
            print(f"   - æ€»æ—¶é—´: {metrics['total_time']:.1f}s")
            print(f"   - é€Ÿåº¦æå‡: {speedup:.2f}x")
            print(f"   - å†…å­˜ä½¿ç”¨: +{metrics['memory_usage_gb']:.1f}GB")
            if metrics['gpu_memory_usage_gb'] > 0:
                print(f"   - GPUå†…å­˜ä½¿ç”¨: +{metrics['gpu_memory_usage_gb']:.1f}GB")
    
    print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {args.output}")

if __name__ == "__main__":
    main()