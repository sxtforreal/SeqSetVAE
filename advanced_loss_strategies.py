"""
Advanced Loss Function Strategies for Medical Classification
å¤šç§æŸå¤±å‡½æ•°ç»„åˆç­–ç•¥ï¼Œç”¨äºæå‡AUCå’ŒAUPRCæ€§èƒ½
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
from losses import FocalLoss


class DiversifiedLossStrategy:
    """
    å¤šæ ·åŒ–æŸå¤±ç­–ç•¥ç±»
    ä¸»è¦ç›®æ ‡ï¼šé€šè¿‡ä¸åŒçš„æŸå¤±å‡½æ•°ç»„åˆï¼Œè®©ä¸»è¾…åŠ©å¤´å­¦ä¹ äº’è¡¥çš„è¡¨ç¤º
    """
    
    def __init__(self, strategy="balanced", focal_alpha=0.2, focal_gamma=2.5):
        self.strategy = strategy
        self.focal_loss = FocalLoss(alpha=focal_alpha, gamma=focal_gamma, reduction="mean")
        
    def compute_loss(self, main_logits, aux_logits, labels):
        """
        è®¡ç®—å¤šæ ·åŒ–æŸå¤±
        
        Args:
            main_logits: ä¸»é¢„æµ‹å¤´çš„logits [B, num_classes]
            aux_logits: è¾…åŠ©é¢„æµ‹å¤´çš„logits [B, num_classes] 
            labels: çœŸå®æ ‡ç­¾ [B]
            
        Returns:
            total_loss: æ€»æŸå¤±
            loss_dict: å„ç»„ä»¶æŸå¤±çš„å­—å…¸
        """
        
        if self.strategy == "balanced":
            return self._balanced_strategy(main_logits, aux_logits, labels)
        elif self.strategy == "focal_smooth":
            return self._focal_smooth_strategy(main_logits, aux_logits, labels)
        elif self.strategy == "confidence_aware":
            return self._confidence_aware_strategy(main_logits, aux_logits, labels)
        elif self.strategy == "adversarial":
            return self._adversarial_strategy(main_logits, aux_logits, labels)
        else:
            raise ValueError(f"Unknown strategy: {self.strategy}")
    
    def _balanced_strategy(self, main_logits, aux_logits, labels):
        """
        å¹³è¡¡ç­–ç•¥ï¼šä¸»å¤´ç”¨Focal Lossï¼Œè¾…åŠ©å¤´ç”¨å¹³æ»‘äº¤å‰ç†µ
        é€‚ç”¨äºå¤§å¤šæ•°ä¸å¹³è¡¡åˆ†ç±»ä»»åŠ¡
        """
        # ä¸»æŸå¤±ï¼šFocal Loss (å¤„ç†ç±»åˆ«ä¸å¹³è¡¡å’Œå›°éš¾æ ·æœ¬)
        main_loss = self.focal_loss(main_logits, labels)
        
        # è¾…åŠ©æŸå¤±ï¼šæ ‡ç­¾å¹³æ»‘äº¤å‰ç†µ (æ›´å¹³æ»‘çš„æ¦‚ç‡åˆ†å¸ƒ)
        aux_loss = F.cross_entropy(aux_logits, labels, label_smoothing=0.15)
        
        # ä¸€è‡´æ€§æŸå¤±ï¼šé¼“åŠ±ä¸¤ä¸ªå¤´å­¦ä¹ ç›¸ä¼¼ä½†ä¸å®Œå…¨ç›¸åŒçš„è¡¨ç¤º
        main_probs = F.softmax(main_logits, dim=1)
        consistency_loss = F.kl_div(
            F.log_softmax(aux_logits, dim=1),
            main_probs.detach(),
            reduction='batchmean'
        )
        
        # ç»„åˆæŸå¤± (70% + 25% + 5%)
        total_loss = 0.7 * main_loss + 0.25 * aux_loss + 0.05 * consistency_loss
        
        return total_loss, {
            'main_loss': main_loss,
            'aux_loss': aux_loss, 
            'consistency_loss': consistency_loss
        }
    
    def _focal_smooth_strategy(self, main_logits, aux_logits, labels):
        """
        Focal+å¹³æ»‘ç­–ç•¥ï¼šé’ˆå¯¹ä¸¥é‡ä¸å¹³è¡¡çš„åŒ»ç–—æ•°æ®
        """
        # ä¸»æŸå¤±ï¼šæ ‡å‡†Focal Loss
        main_loss = self.focal_loss(main_logits, labels)
        
        # è¾…åŠ©æŸå¤±ï¼šæ›´å¼ºçš„æ ‡ç­¾å¹³æ»‘ + æ¸©åº¦ç¼©æ”¾
        temperature = 2.0  # è½¯åŒ–æ¦‚ç‡åˆ†å¸ƒ
        aux_loss = F.cross_entropy(aux_logits / temperature, labels, label_smoothing=0.2)
        
        # å¤šæ ·æ€§æŸå¤±ï¼šé¼“åŠ±ä¸¤ä¸ªå¤´å­¦ä¹ ä¸åŒçš„è¡¨ç¤º
        main_probs = F.softmax(main_logits, dim=1)
        aux_probs = F.softmax(aux_logits, dim=1)
        diversity_loss = -F.kl_div(
            F.log_softmax(aux_logits, dim=1),
            main_probs.detach(),
            reduction='batchmean'
        )  # è´ŸKLæ•£åº¦é¼“åŠ±å¤šæ ·æ€§
        
        # ç»„åˆæŸå¤± (60% + 30% + 10%)
        total_loss = 0.6 * main_loss + 0.3 * aux_loss + 0.1 * diversity_loss
        
        return total_loss, {
            'main_loss': main_loss,
            'aux_loss': aux_loss,
            'diversity_loss': diversity_loss
        }
    
    def _confidence_aware_strategy(self, main_logits, aux_logits, labels):
        """
        ç½®ä¿¡åº¦æ„ŸçŸ¥ç­–ç•¥ï¼šæ ¹æ®é¢„æµ‹ç½®ä¿¡åº¦åŠ¨æ€è°ƒæ•´æŸå¤±æƒé‡
        """
        # è®¡ç®—ä¸»å¤´çš„ç½®ä¿¡åº¦
        main_probs = F.softmax(main_logits, dim=1)
        main_confidence = torch.max(main_probs, dim=1)[0]  # æœ€å¤§æ¦‚ç‡ä½œä¸ºç½®ä¿¡åº¦
        
        # ä¸»æŸå¤±ï¼šFocal Loss
        main_loss = self.focal_loss(main_logits, labels)
        
        # è¾…åŠ©æŸå¤±ï¼šå¯¹ä½ç½®ä¿¡åº¦æ ·æœ¬ç»™äºˆæ›´å¤šæƒé‡
        aux_loss_raw = F.cross_entropy(aux_logits, labels, reduction='none')
        confidence_weights = 1.0 - main_confidence.detach()  # ä½ç½®ä¿¡åº¦â†’é«˜æƒé‡
        aux_loss = (aux_loss_raw * confidence_weights).mean()
        
        # æ ¡å‡†æŸå¤±ï¼šæé«˜æ¦‚ç‡æ ¡å‡†è´¨é‡
        calibration_loss = F.mse_loss(main_confidence, (main_probs.argmax(dim=1) == labels).float())
        
        # åŠ¨æ€æƒé‡ç»„åˆ
        avg_confidence = main_confidence.mean()
        main_weight = 0.5 + 0.3 * avg_confidence  # é«˜ç½®ä¿¡åº¦â†’æ›´å¤šä¸»æŸå¤±æƒé‡
        aux_weight = 0.5 - 0.2 * avg_confidence   # ä½ç½®ä¿¡åº¦â†’æ›´å¤šè¾…åŠ©æŸå¤±æƒé‡
        
        total_loss = main_weight * main_loss + aux_weight * aux_loss + 0.1 * calibration_loss
        
        return total_loss, {
            'main_loss': main_loss,
            'aux_loss': aux_loss,
            'calibration_loss': calibration_loss,
            'avg_confidence': avg_confidence
        }
    
    def _adversarial_strategy(self, main_logits, aux_logits, labels):
        """
        å¯¹æŠ—ç­–ç•¥ï¼šè¾…åŠ©å¤´å°è¯•"å¯¹æŠ—"ä¸»å¤´ï¼Œæå‡é²æ£’æ€§
        """
        # ä¸»æŸå¤±ï¼šFocal Loss
        main_loss = self.focal_loss(main_logits, labels)
        
        # è¾…åŠ©æŸå¤±ï¼šæ ‡å‡†äº¤å‰ç†µ
        aux_loss = F.cross_entropy(aux_logits, labels)
        
        # å¯¹æŠ—æŸå¤±ï¼šæœ€å¤§åŒ–ä¸»è¾…åŠ©å¤´é¢„æµ‹çš„å·®å¼‚ï¼ˆåœ¨æ­£ç¡®é¢„æµ‹çš„å‰æä¸‹ï¼‰
        main_probs = F.softmax(main_logits, dim=1)
        aux_probs = F.softmax(aux_logits, dim=1)
        
        # åªå¯¹æ­£ç¡®é¢„æµ‹çš„æ ·æœ¬è®¡ç®—å¯¹æŠ—æŸå¤±
        main_correct = (main_logits.argmax(dim=1) == labels)
        aux_correct = (aux_logits.argmax(dim=1) == labels)
        both_correct = main_correct & aux_correct
        
        if both_correct.sum() > 0:
            adversarial_loss = -F.kl_div(
                F.log_softmax(aux_logits[both_correct], dim=1),
                main_probs[both_correct].detach(),
                reduction='batchmean'
            )
        else:
            adversarial_loss = torch.tensor(0.0, device=main_logits.device)
        
        # ç»„åˆæŸå¤±
        total_loss = 0.6 * main_loss + 0.3 * aux_loss + 0.1 * adversarial_loss
        
        return total_loss, {
            'main_loss': main_loss,
            'aux_loss': aux_loss,
            'adversarial_loss': adversarial_loss,
            'both_correct_ratio': both_correct.float().mean()
        }


# é…ç½®ä¸åŒç­–ç•¥çš„æ¨èå‚æ•°
STRATEGY_CONFIGS = {
    "balanced": {
        "description": "å¹³è¡¡ç­–ç•¥ - é€‚ç”¨äºè½»åº¦åˆ°ä¸­åº¦ä¸å¹³è¡¡æ•°æ®",
        "focal_alpha": 0.2,
        "focal_gamma": 2.5,
        "best_for": "ä¸€èˆ¬åŒ»ç–—åˆ†ç±»ä»»åŠ¡"
    },
    "focal_smooth": {
        "description": "Focal+å¹³æ»‘ç­–ç•¥ - é€‚ç”¨äºä¸¥é‡ä¸å¹³è¡¡æ•°æ®", 
        "focal_alpha": 0.15,
        "focal_gamma": 3.0,
        "best_for": "ç½•è§ç–¾ç—…æ£€æµ‹ï¼Œä¸¥é‡ä¸å¹³è¡¡æ•°æ®"
    },
    "confidence_aware": {
        "description": "ç½®ä¿¡åº¦æ„ŸçŸ¥ç­–ç•¥ - é€‚ç”¨äºéœ€è¦æ¦‚ç‡æ ¡å‡†çš„ä»»åŠ¡",
        "focal_alpha": 0.25,
        "focal_gamma": 2.0,
        "best_for": "é£é™©è¯„ä¼°ï¼Œéœ€è¦å‡†ç¡®æ¦‚ç‡çš„ä»»åŠ¡"
    },
    "adversarial": {
        "description": "å¯¹æŠ—ç­–ç•¥ - é€‚ç”¨äºéœ€è¦æå‡é²æ£’æ€§çš„ä»»åŠ¡",
        "focal_alpha": 0.2,
        "focal_gamma": 2.5,
        "best_for": "å™ªå£°æ•°æ®ï¼Œæå‡æ¨¡å‹é²æ£’æ€§"
    }
}


def get_recommended_strategy(class_imbalance_ratio, noise_level="low", requires_calibration=False):
    """
    æ ¹æ®æ•°æ®ç‰¹å¾æ¨èæœ€ä½³ç­–ç•¥
    
    Args:
        class_imbalance_ratio: ç±»åˆ«ä¸å¹³è¡¡æ¯”ä¾‹ (minority/majority)
        noise_level: æ•°æ®å™ªå£°æ°´å¹³ ("low", "medium", "high")
        requires_calibration: æ˜¯å¦éœ€è¦æ¦‚ç‡æ ¡å‡†
        
    Returns:
        strategy_name: æ¨èçš„ç­–ç•¥åç§°
    """
    if requires_calibration:
        return "confidence_aware"
    elif class_imbalance_ratio < 0.1:  # ä¸¥é‡ä¸å¹³è¡¡
        return "focal_smooth"
    elif noise_level == "high":
        return "adversarial"
    else:
        return "balanced"  # é»˜è®¤é€‰æ‹©


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    print("ğŸ¯ é«˜çº§æŸå¤±ç­–ç•¥é…ç½®")
    print("=" * 50)
    
    for strategy, config in STRATEGY_CONFIGS.items():
        print(f"\nğŸ“‹ {strategy.upper()}:")
        print(f"   æè¿°: {config['description']}")
        print(f"   é€‚ç”¨äº: {config['best_for']}")
        print(f"   å‚æ•°: Î±={config['focal_alpha']}, Î³={config['focal_gamma']}")
    
    print(f"\nğŸ”§ æ¨èç­–ç•¥ç¤ºä¾‹:")
    print(f"   è½»åº¦ä¸å¹³è¡¡ (1:5): {get_recommended_strategy(0.2)}")
    print(f"   ä¸­åº¦ä¸å¹³è¡¡ (1:10): {get_recommended_strategy(0.1)}")
    print(f"   ä¸¥é‡ä¸å¹³è¡¡ (1:50): {get_recommended_strategy(0.02)}")
    print(f"   éœ€è¦æ¦‚ç‡æ ¡å‡†: {get_recommended_strategy(0.2, requires_calibration=True)}")